{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 8000)\n",
      "0.9070532598287184\n",
      "0\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9670967741935484\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9676344086021504\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9638709677419355\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "87 207\n",
      "准确率为0.9575268817204302\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.903415335361\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "88 207\n",
      "准确率为0.960752688172043\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91078982116\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "88 206\n",
      "准确率为0.957741935483871\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为0.9903846153846154\n",
      "MCC为0.902863569488\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "86 208\n",
      "准确率为0.9575268817204302\n",
      "正类召回率为0.8686868686868687\n",
      "负类召回率为1.0\n",
      "MCC为0.904205530351\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387098\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9705376344086021\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "91 208\n",
      "准确率为0.9737634408602152\n",
      "正类召回率为0.9191919191919192\n",
      "负类召回率为1.0\n",
      "MCC为0.940822923847\n",
      "0.973941368078\n",
      "SVM的测试集结果：\n",
      "85 208\n",
      "准确率为0.9541935483870969\n",
      "正类召回率为0.8585858585858586\n",
      "负类召回率为1.0\n",
      "MCC为0.896906240608\n",
      "0.954397394137\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9670967741935484\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "85 208\n",
      "准确率为0.954516129032258\n",
      "正类召回率为0.8585858585858586\n",
      "负类召回率为1.0\n",
      "MCC为0.896906240608\n",
      "0.954397394137\n",
      "SVM的测试集结果：\n",
      "89 206\n",
      "准确率为0.9609677419354838\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9903846153846154\n",
      "MCC为0.910303837032\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 207\n",
      "准确率为0.9640860215053764\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91817225809\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "90 207\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.92556338044\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "86 207\n",
      "准确率为0.954516129032258\n",
      "正类召回率为0.8686868686868687\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.896048059424\n",
      "0.954397394137\n",
      "SVM的测试集结果：\n",
      "92 208\n",
      "准确率为0.9774193548387096\n",
      "正类召回率为0.9292929292929293\n",
      "负类召回率为1.0\n",
      "MCC为0.948175553593\n",
      "0.977198697068\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9608602150537635\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "85 207\n",
      "准确率为0.9513978494623656\n",
      "正类召回率为0.8585858585858586\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.888687244471\n",
      "0.951140065147\n",
      "SVM的测试集结果：\n",
      "93 208\n",
      "准确率为0.9804301075268818\n",
      "正类召回率为0.9393939393939394\n",
      "负类召回率为1.0\n",
      "MCC为0.955539529041\n",
      "0.980456026059\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9707526881720432\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9641935483870968\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9708602150537635\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "90 207\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.92556338044\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 206\n",
      "准确率为0.9609677419354838\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9903846153846154\n",
      "MCC为0.910303837032\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9708602150537635\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9605376344086022\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387098\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "85 208\n",
      "准确率为0.9546236559139786\n",
      "正类召回率为0.8585858585858586\n",
      "负类召回率为1.0\n",
      "MCC为0.896906240608\n",
      "0.954397394137\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9676344086021504\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9609677419354838\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 206\n",
      "准确率为0.9606451612903226\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9903846153846154\n",
      "MCC为0.910303837032\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 207\n",
      "准确率为0.9641935483870968\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91817225809\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "87 207\n",
      "准确率为0.9576344086021505\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.903415335361\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9609677419354841\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9673118279569893\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.963978494623656\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "91 207\n",
      "准确率为0.9705376344086023\n",
      "正类召回率为0.9191919191919192\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.932963916106\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "88 207\n",
      "准确率为0.9610752688172044\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91078982116\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9611827956989247\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "87 207\n",
      "准确率为0.9576344086021505\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.903415335361\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9641935483870968\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "89 207\n",
      "准确率为0.9644086021505377\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91817225809\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9638709677419355\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "86 208\n",
      "准确率为0.9576344086021505\n",
      "正类召回率为0.8686868686868687\n",
      "负类召回率为1.0\n",
      "MCC为0.904205530351\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "89 207\n",
      "准确率为0.9643010752688171\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91817225809\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "83 208\n",
      "准确率为0.9481720430107528\n",
      "正类召回率为0.8383838383838383\n",
      "负类召回率为1.0\n",
      "MCC为0.882326061328\n",
      "0.947882736156\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9643010752688171\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "85 208\n",
      "准确率为0.9546236559139786\n",
      "正类召回率为0.8585858585858586\n",
      "负类召回率为1.0\n",
      "MCC为0.896906240608\n",
      "0.954397394137\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9706451612903226\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "86 207\n",
      "准确率为0.9544086021505377\n",
      "正类召回率为0.8686868686868687\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.896048059424\n",
      "0.954397394137\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9673118279569893\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "86 205\n",
      "准确率为0.9479569892473119\n",
      "正类召回率为0.8686868686868687\n",
      "负类召回率为0.9855769230769231\n",
      "MCC为0.880071614612\n",
      "0.947882736156\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9672043010752688\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "90 207\n",
      "准确率为0.9673118279569893\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.92556338044\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "83 208\n",
      "准确率为0.9472043010752689\n",
      "正类召回率为0.8383838383838383\n",
      "负类召回率为1.0\n",
      "MCC为0.882326061328\n",
      "0.947882736156\n",
      "SVM的测试集结果：\n",
      "85 207\n",
      "准确率为0.9507526881720431\n",
      "正类召回率为0.8585858585858586\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.888687244471\n",
      "0.951140065147\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9707526881720432\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "87 207\n",
      "准确率为0.9576344086021505\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.903415335361\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "88 207\n",
      "准确率为0.9609677419354838\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91078982116\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "90 207\n",
      "准确率为0.9670967741935484\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.92556338044\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "87 207\n",
      "准确率为0.9576344086021505\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.903415335361\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9643010752688174\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9608602150537635\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "84 208\n",
      "准确率为0.9511827956989247\n",
      "正类召回率为0.8484848484848485\n",
      "负类召回率为1.0\n",
      "MCC为0.889613329831\n",
      "0.951140065147\n",
      "SVM的测试集结果：\n",
      "91 208\n",
      "准确率为0.9740860215053763\n",
      "正类召回率为0.9191919191919192\n",
      "负类召回率为1.0\n",
      "MCC为0.940822923847\n",
      "0.973941368078\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "87 207\n",
      "准确率为0.9573118279569893\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.903415335361\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "89 207\n",
      "准确率为0.9643010752688171\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91817225809\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9706451612903226\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9637634408602151\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.9706451612903226\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "88 207\n",
      "准确率为0.960752688172043\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91078982116\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 207\n",
      "准确率为0.9640860215053764\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91817225809\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "87 207\n",
      "准确率为0.957741935483871\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.903415335361\n",
      "0.957654723127\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9640860215053764\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9673118279569893\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "90 207\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.92556338044\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9606451612903226\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "90 208\n",
      "准确率为0.970752688172043\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为1.0\n",
      "MCC为0.933480946693\n",
      "0.970684039088\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "86 206\n",
      "准确率为0.9512903225806453\n",
      "正类召回率为0.8686868686868687\n",
      "负类召回率为0.9903846153846154\n",
      "MCC为0.888004516449\n",
      "0.951140065147\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.9609677419354838\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387097\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.9644086021505377\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "88 208\n",
      "准确率为0.964516129032258\n",
      "正类召回率为0.8888888888888888\n",
      "负类召回率为1.0\n",
      "MCC为0.918826154273\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "84 208\n",
      "准确率为0.9510752688172044\n",
      "正类召回率为0.8484848484848485\n",
      "负类召回率为1.0\n",
      "MCC为0.889613329831\n",
      "0.951140065147\n",
      "SVM的测试集结果：\n",
      "87 208\n",
      "准确率为0.960752688172043\n",
      "正类召回率为0.8787878787878788\n",
      "负类召回率为1.0\n",
      "MCC为0.911511927783\n",
      "0.960912052117\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9675268817204301\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 208\n",
      "准确率为0.9674193548387098\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为1.0\n",
      "MCC为0.926148924433\n",
      "0.967426710098\n",
      "SVM的测试集结果：\n",
      "89 207\n",
      "准确率为0.9643010752688171\n",
      "正类召回率为0.898989898989899\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.91817225809\n",
      "0.964169381107\n",
      "SVM的测试集结果：\n",
      "90 207\n",
      "准确率为0.9673118279569893\n",
      "正类召回率为0.9090909090909091\n",
      "负类召回率为0.9951923076923077\n",
      "MCC为0.92556338044\n",
      "0.967426710098\n"
     ]
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import itertools as iters\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pylab as plt\n",
    "from math import log2 \n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def entropy(data):\n",
    "    length,dataDict=len(data),{} \n",
    "    for b in data:  \n",
    "        try:dataDict[b]+=1  \n",
    "        except:dataDict[b]=1  \n",
    "    entropy=sum([-d/length*log2(d/length) for d in list(dataDict.values())])\n",
    "    return entropy\n",
    "\n",
    "def informationgain(data,label):\n",
    "    informationgain = []\n",
    "    la = entropy(label)\n",
    "    print(la)\n",
    "    for j in range(data.shape[1] ):\n",
    "        feature = data[:,j]\n",
    "        for a in set(feature):\n",
    "            ent = []\n",
    "            op = []\n",
    "            ne = []\n",
    "            for k in range(len(feature)):\n",
    "                if feature[k] >= a:\n",
    "                    op.append(label[k])\n",
    "                else:\n",
    "                    ne.append(label[k])\n",
    "            if len(op) == 0 or len(ne) == 0:\n",
    "                ent.append(la)\n",
    "            else:\n",
    "                ent.append(len(op)*entropy(op)/len(label) + len(ne)*entropy(ne)/len(label))\n",
    "        informationgain.append(la-min(ent))\n",
    "    return informationgain\n",
    "\n",
    "##计算三肽特征\n",
    "def statisPsi_3(seqs,protein,gap1,gap2):\n",
    "    psi = np.zeros(len(seqs))\n",
    "    loops = len(protein) - gap1 - gap2 - 2\n",
    "    for start in range(loops):\n",
    "        dipeptide = protein[start] + protein[start + gap1 + 1] + protein[start + 2 + gap1 + gap2]\n",
    "        index = seqs.index(dipeptide)\n",
    "        psi[index] += 1\n",
    "    psi = np.array(psi)\n",
    "    psi = psi / sum(psi)\n",
    "    return psi\n",
    "\n",
    "# get gap dipeptide features psi matrix\",\n",
    "def all_psi(dataset,gap1,gap2):\n",
    "    gap_psi = np.zeros((len(dataset), len(DIPEPTIDE)))\n",
    "    for idx in range(len(dataset)):\n",
    "        gap_psi[idx] = statisPsi_3(DIPEPTIDE, dataset[idx], gap1,gap2)\n",
    "    return gap_psi\n",
    "\n",
    "#输入核函数名称和参数gamma值，返回SVM训练十折交叉验证的准确率\n",
    "def SVM_10fold(data,label):\n",
    "    ##数据归一化（按列处理，必须做）\n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    kf = KFold(data.shape[0],n_folds=10,shuffle = True)  #固定随机数可固定分组\n",
    "    precision_average = 0.0\n",
    "    TPCount = 0\n",
    "    TNCount = 0\n",
    "    train = []\n",
    "    test = []\n",
    "    test_true = []\n",
    "\n",
    "    C_range = np.logspace(15, 5, 11, base=2)\n",
    "    gamma_range = np.logspace(-15, -25, 11, base=2)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    grid = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, cv=5)  # 基于交叉验证的网格搜索\n",
    "\n",
    "    for train_index, test_index in kf:\n",
    "        grid = grid.fit(data[train_index],label[train_index])\n",
    "        clf = SVC(C = grid.best_params_['C'],gamma=grid.best_params_['gamma'])\n",
    "        clf.fit(data[train_index],label[train_index])\n",
    "        pred_train = clf.predict(data[train_index]).tolist()\n",
    "        pred_test = clf.predict(data[test_index]).tolist()\n",
    "\n",
    "        train.append(pred_train)\n",
    "        test = test + pred_test\n",
    "        test_true = test_true + label[test_index].tolist()\n",
    "\n",
    "        testLabel = label[test_index]\n",
    "\n",
    "        # print(metrics.confusion_matrix(pred_train,trainLabel))\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        #同时输出svm的结果\n",
    "        #查看测试集的结果\n",
    "        for i in range(len(pred_test)):\n",
    "            if pred_test[i] == 1 and (testLabel[i] == 1):\n",
    "                TP = TP + 1\n",
    "            elif pred_test[i] == 0 and (testLabel[i] == 0):\n",
    "                TN = TN + 1\n",
    "        TPCount = TPCount + TP\n",
    "        TNCount = TNCount + TN\n",
    "\n",
    "        precision = (TP + TN) * 1.0 / len(testLabel)\n",
    "        precision_average = precision_average + precision\n",
    "\n",
    "\n",
    "    precision_average = precision_average / 10\n",
    "    positiveReca1 = TPCount * 1.0 / 99\n",
    "    negtiveReca1 = TNCount * 1.0 / 208\n",
    "    MCC = matthews_corrcoef(test_true,test)\n",
    "\n",
    "\n",
    "    print (u'SVM的测试集结果：')\n",
    "    print (TPCount,TNCount)\n",
    "    print (u'准确率为' + str(precision_average))\n",
    "    print (u'正类召回率为' + str(positiveReca1))\n",
    "    print (u'负类召回率为' + str(negtiveReca1))\n",
    "    print(u'MCC为' + str(matthews_corrcoef(test_true,test)))\n",
    "    print(accuracy_score(test_true,test))\n",
    "\n",
    "\n",
    "    # ##保存最优模型的训练、测试集结果\n",
    "    # with open('C:\\\\Users\\Administrator\\Desktop\\data\\\\result\\\\result_4gapTC_svm_train.txt','w') as file:\n",
    "    #     for i in train:\n",
    "    #         file.write(str(i) + '\\n')\n",
    "    # with open('C:\\\\Users\\Administrator\\Desktop\\data\\\\result\\\\result_4gapTC_svm_test.txt','w') as file:\n",
    "    #     for i in test:\n",
    "    #         file.write(str(i) + '\\n')\n",
    "\n",
    "\n",
    "    return precision_average,positiveReca1,negtiveReca1,MCC\n",
    "\n",
    "if(__name__=='__main__'):\n",
    "    # t0 = time()\n",
    "    path = r''\n",
    "    with open('virion.txt', \"r\") as file:\n",
    "        train_tdata = [line.strip() for line in file if '>' != line[0]]\n",
    "    with open( 'non-virion.txt', \"r\") as file:\n",
    "        train_fdata = [line.strip() for line in file if '>' != line[0]]\n",
    "\n",
    "    SAA = ('ACDEFGHIKLMNPQRSTVWY')\n",
    "    DIPEPTIDE = []\n",
    "\n",
    "    for dipeptide in iters.product(SAA, repeat=3):\n",
    "        DIPEPTIDE.append(''.join(dipeptide))\n",
    "\n",
    "    label = pd.Series([1 for i in range(len(train_tdata))]+ [0 for i in range(len(train_fdata))])\n",
    "    label = label.as_matrix()\n",
    "\n",
    "    ##将序列处理为特征向量\n",
    "    ##gap1 和 gap2 的数值是任意选取的，一般是从0到10遍历寻优的，但是那样太浪费时间了，你可以先直接指定一个值先看效果\n",
    "\n",
    "    gap1 = 2\n",
    "    gap2 = 1\n",
    "    gap_T = all_psi(train_tdata,gap1,gap2)\n",
    "    gap_F = all_psi(train_fdata,gap1,gap2)\n",
    "\n",
    "    dataAll = np.row_stack((gap_T, gap_F))  # 矩阵按行合并\n",
    "    # print(data.shape)\n",
    "    ##将特征结果保存，方便下次直接读取\n",
    "    # np.savetxt('E:\\Python Program\\Protein\\data\\gapAll\\\\virion_gap0_dipe2.csv', data, delimiter=',')\n",
    "    ##直接读入特征数据\n",
    "    # dataAll = pd.read_csv(path = '\\\\virion_gap0_dipe2.csv',header=None).as_matrix()\n",
    "\n",
    "\n",
    "    print(dataAll.shape)\n",
    "    ##计算F值\n",
    "    f = informationgain(dataAll,label)\n",
    "\n",
    "    ##因为三肽特征较为稀疏，会有一些全为nan的列，要对这些列进行处理\n",
    "    a = np.array(f)\n",
    "    nan_count = np.sum(a != a)\n",
    "    print(nan_count)\n",
    "    ##将nan替换为0\n",
    "    f1 = np.nan_to_num(a)\n",
    "    ##将F值从大到小排序，获得相应的位置序号\n",
    "    f_order = np.argsort(f1).tolist()[::-1]\n",
    "    #选取所需的特征维度，构造模型，如这里是前100维特征，这个数值按照需要也可以更改\n",
    "    p = []\n",
    "    n = 771\n",
    "    data = dataAll[:,f_order[0:n]]\n",
    "\n",
    "    for cishu in range(103):\n",
    "        presion,positiveRecall,negtiveRecall,matthews = SVM_10fold(data,label)\n",
    "        acc.append(presion)\n",
    "        pr.append(positiveRecall)\n",
    "        nr.append(negtiveRecall)\n",
    "        MCC.append(matthews)\n",
    "        \n",
    "#             p.append(presion)\n",
    "#         np.savetxt('./新增/'+ str(gap1) + str(gap2)+'informationgain.csv',p,delimiter=',')\n",
    "\n",
    "    ###为了选取最优特征子集，一般需要遍历，结果运行、保存、展示如下\n",
    "#     p = []\n",
    "#     for i in range(1,800,10):\n",
    "#         data = dataAll[:, f_order[0:i]]\n",
    "#         print(data.shape)\n",
    "#         presion, positiveRecall, negtiveRecall = SVM_10fold(data, label)\n",
    "#         p.append(presion)\n",
    "#     # print(SVM_10fold(data,label))\n",
    "#     np.savetxt(str(gap1) + 'and' + str(gap2) + 'informationgainstatisPsi_3.csv',p,delimiter=',')\n",
    "#     plt.plot(range(len(p)),p)\n",
    "#     plt.savefig(str(gap1) +'and' + str(gap2) + 'informationgainstatisPsi_3.pdf')\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307, 8000)\n",
      "0.9070532598287184\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import itertools as iters\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pylab as plt\n",
    "from math import log2 \n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def entropy(data):\n",
    "    length,dataDict=len(data),{} \n",
    "    for b in data:  \n",
    "        try:dataDict[b]+=1  \n",
    "        except:dataDict[b]=1  \n",
    "    entropy=sum([-d/length*log2(d/length) for d in list(dataDict.values())])\n",
    "    return entropy\n",
    "\n",
    "def informationgain(data,label):\n",
    "    informationgain = []\n",
    "    la = entropy(label)\n",
    "    print(la)\n",
    "    for j in range(data.shape[1] ):\n",
    "        feature = data[:,j]\n",
    "        for a in set(feature):\n",
    "            ent = []\n",
    "            op = []\n",
    "            ne = []\n",
    "            for k in range(len(feature)):\n",
    "                if feature[k] >= a:\n",
    "                    op.append(label[k])\n",
    "                else:\n",
    "                    ne.append(label[k])\n",
    "            if len(op) == 0 or len(ne) == 0:\n",
    "                ent.append(la)\n",
    "            else:\n",
    "                ent.append(len(op)*entropy(op)/len(label) + len(ne)*entropy(ne)/len(label))\n",
    "        informationgain.append(la-min(ent))\n",
    "    return informationgain\n",
    "\n",
    "##计算三肽特征\n",
    "def statisPsi_3(seqs,protein,gap1,gap2):\n",
    "    psi = np.zeros(len(seqs))\n",
    "    loops = len(protein) - gap1 - gap2 - 2\n",
    "    for start in range(loops):\n",
    "        dipeptide = protein[start] + protein[start + gap1 + 1] + protein[start + 2 + gap1 + gap2]\n",
    "        index = seqs.index(dipeptide)\n",
    "        psi[index] += 1\n",
    "    psi = np.array(psi)\n",
    "    psi = psi / sum(psi)\n",
    "    return psi\n",
    "\n",
    "# get gap dipeptide features psi matrix\",\n",
    "def all_psi(dataset,gap1,gap2):\n",
    "    gap_psi = np.zeros((len(dataset), len(DIPEPTIDE)))\n",
    "    for idx in range(len(dataset)):\n",
    "        gap_psi[idx] = statisPsi_3(DIPEPTIDE, dataset[idx], gap1,gap2)\n",
    "    return gap_psi\n",
    "\n",
    "#输入核函数名称和参数gamma值，返回SVM训练十折交叉验证的准确率\n",
    "def SVM_10fold(data,label):\n",
    "    ##数据归一化（按列处理，必须做）\n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    kf = KFold(data.shape[0],n_folds=10,shuffle = True,random_state=100)  #固定随机数可固定分组\n",
    "    precision_average = 0.0\n",
    "    TPCount = 0\n",
    "    TNCount = 0\n",
    "    train = []\n",
    "    test = []\n",
    "    test_true = []\n",
    "\n",
    "    C_range = np.logspace(15, 5, 11, base=2)\n",
    "    gamma_range = np.logspace(-15, -25, 11, base=2)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    grid = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, cv=5)  # 基于交叉验证的网格搜索\n",
    "\n",
    "    for train_index, test_index in kf:\n",
    "        grid = grid.fit(data[train_index],label[train_index])\n",
    "        clf = SVC(C = grid.best_params_['C'],gamma=grid.best_params_['gamma'],probability=True)\n",
    "        clf.fit(data[train_index],label[train_index])\n",
    "        pred_train = clf.predict(data[train_index]).tolist()\n",
    "        pred_test = clf.predict(data[test_index]).tolist()\n",
    "\n",
    "        train.append(pred_train)\n",
    "        test = test + pred_test\n",
    "        test_true = test_true + label[test_index].tolist()\n",
    "\n",
    "        testLabel = label[test_index]\n",
    "\n",
    "        # print(metrics.confusion_matrix(pred_train,trainLabel))\n",
    "        TP = 0\n",
    "        TN = 0\n",
    "        #同时输出svm的结果\n",
    "        #查看测试集的结果\n",
    "        for i in range(len(pred_test)):\n",
    "            if pred_test[i] == 1 and (testLabel[i] == 1):\n",
    "                TP = TP + 1\n",
    "            elif pred_test[i] == 0 and (testLabel[i] == 0):\n",
    "                TN = TN + 1\n",
    "        TPCount = TPCount + TP\n",
    "        TNCount = TNCount + TN\n",
    "\n",
    "        precision = (TP + TN) * 1.0 / len(testLabel)\n",
    "        precision_average = precision_average + precision\n",
    "\n",
    "\n",
    "    precision_average = precision_average / 10\n",
    "    positiveReca1 = TPCount * 1.0 / 99\n",
    "    negtiveReca1 = TNCount * 1.0 / 208\n",
    "\n",
    "\n",
    "    print (u'SVM的测试集结果：')\n",
    "    print (TPCount,TNCount)\n",
    "    print (u'准确率为' + str(precision_average))\n",
    "    print (u'正类召回率为' + str(positiveReca1))\n",
    "    print (u'负类召回率为' + str(negtiveReca1))\n",
    "    print(u'MCC为' + str(matthews_corrcoef(test_true,test)))\n",
    "    print(accuracy_score(test_true,test))\n",
    "\n",
    "\n",
    "    # ##保存最优模型的训练、测试集结果\n",
    "    # with open('C:\\\\Users\\Administrator\\Desktop\\data\\\\result\\\\result_4gapTC_svm_train.txt','w') as file:\n",
    "    #     for i in train:\n",
    "    #         file.write(str(i) + '\\n')\n",
    "    # with open('C:\\\\Users\\Administrator\\Desktop\\data\\\\result\\\\result_4gapTC_svm_test.txt','w') as file:\n",
    "    #     for i in test:\n",
    "    #         file.write(str(i) + '\\n')\n",
    "\n",
    "\n",
    "    return precision_average,positiveReca1,negtiveReca1\n",
    "\n",
    "if(__name__=='__main__'):\n",
    "    # t0 = time()\n",
    "    path = r''\n",
    "    with open('virion.txt', \"r\") as file:\n",
    "        train_tdata = [line.strip() for line in file if '>' != line[0]]\n",
    "    with open( 'non-virion.txt', \"r\") as file:\n",
    "        train_fdata = [line.strip() for line in file if '>' != line[0]]\n",
    "\n",
    "    SAA = ('ACDEFGHIKLMNPQRSTVWY')\n",
    "    DIPEPTIDE = []\n",
    "\n",
    "    for dipeptide in iters.product(SAA, repeat=3):\n",
    "        DIPEPTIDE.append(''.join(dipeptide))\n",
    "\n",
    "    label = pd.Series([1 for i in range(len(train_tdata))]+ [0 for i in range(len(train_fdata))])\n",
    "    label = label.as_matrix()\n",
    "\n",
    "    ##将序列处理为特征向量\n",
    "    ##gap1 和 gap2 的数值是任意选取的，一般是从0到10遍历寻优的，但是那样太浪费时间了，你可以先直接指定一个值先看效果\n",
    "\n",
    "    gap1 = 2\n",
    "    gap2 = 1\n",
    "    gap_T = all_psi(train_tdata,gap1,gap2)\n",
    "    gap_F = all_psi(train_fdata,gap1,gap2)\n",
    "\n",
    "    dataAll = np.row_stack((gap_T, gap_F))  # 矩阵按行合并\n",
    "    # print(data.shape)\n",
    "    ##将特征结果保存，方便下次直接读取\n",
    "    # np.savetxt('E:\\Python Program\\Protein\\data\\gapAll\\\\virion_gap0_dipe2.csv', data, delimiter=',')\n",
    "    ##直接读入特征数据\n",
    "    # dataAll = pd.read_csv(path = '\\\\virion_gap0_dipe2.csv',header=None).as_matrix()\n",
    "\n",
    "\n",
    "    print(dataAll.shape)\n",
    "    ##计算F值\n",
    "    f = informationgain(dataAll,label)\n",
    "\n",
    "    ##因为三肽特征较为稀疏，会有一些全为nan的列，要对这些列进行处理\n",
    "    a = np.array(f)\n",
    "    nan_count = np.sum(a != a)\n",
    "    print(nan_count)\n",
    "    ##将nan替换为0\n",
    "    f1 = np.nan_to_num(a)\n",
    "    ##将F值从大到小排序，获得相应的位置序号\n",
    "    f_order = np.argsort(f1).tolist()[::-1]\n",
    "    #选取所需的特征维度，构造模型，如这里是前100维特征，这个数值按照需要也可以更改\n",
    "    p = []\n",
    "    n = 771\n",
    "    data = dataAll[:,f_order[0:n]]\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    C_range = np.logspace(15, 5, 11, base=2)\n",
    "    gamma_range = np.logspace(-15, -25, 11, base=2)\n",
    "    param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "    grid = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid, cv=5)  # 基于交叉验证的网格搜索\n",
    "    grid = grid.fit(data,label)\n",
    "    clf = SVC(C = grid.best_params_['C'],gamma=grid.best_params_['gamma'],probability=True)\n",
    "    clf.fit(data,label)\n",
    "    joblib.dump(clf, \"model.m\")\n",
    "#             p.append(presion)\n",
    "#         np.savetxt('./新增/'+ str(gap1) + str(gap2)+'informationgain.csv',p,delimiter=',')\n",
    "\n",
    "        ###为了选取最优特征子集，一般需要遍历，结果运行、保存、展示如下\n",
    "    #     p = []\n",
    "    #     for i in range(1,800,10):\n",
    "    #         data = dataAll[:, f_order[0:i]]\n",
    "    #         print(data.shape)\n",
    "    #         presion, positiveRecall, negtiveRecall = SVM_10fold(data, label)\n",
    "    #         p.append(presion)\n",
    "    #     # print(SVM_10fold(data,label))\n",
    "    #     np.savetxt(str(gap1) + 'and' + str(gap2) + 'informationgainstatisPsi_3.csv',p,delimiter=',')\n",
    "    #     plt.plot(range(len(p)),p)\n",
    "    #     plt.savefig(str(gap1) +'and' + str(gap2) + 'informationgainstatisPsi_3.pdf')\n",
    "    #     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "0.916173587602\n"
     ]
    }
   ],
   "source": [
    "print(len(MCC))\n",
    "print(np.mean(MCC))\n",
    "a = np.array(MCC)\n",
    "\n",
    "np.savetxt('./3informationgain/MCC.csv',a, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1105, 336, 5383, 5500, 325, 1269, 2056, 1871, 6234, 2316, 6563, 7157, 1268, 4951, 5432, 6651, 100, 149, 6872, 3394, 6958, 5189, 1673, 6032, 2312, 3208, 1377, 3603, 5280, 4667, 6792, 2164, 6323, 6067, 3266, 2862, 16, 6405, 5833, 4804, 6623, 287, 3342, 7791, 1504, 1542, 2919, 7762, 1288, 4469, 3668, 5536, 6592, 6735, 1535, 7140, 2397, 6785, 6495, 1374, 3369, 3, 2307, 7923, 6589, 2083, 2054, 2063, 3455, 5737, 6248, 3289, 3911, 2553, 456, 6666, 3151, 4730, 4681, 1165, 4460, 4240, 2651, 1330, 6729, 500, 3592, 6775, 3242, 7687, 3322, 5064, 973, 327, 5169, 3648, 3743, 2255, 6740, 5795, 6983, 1494, 3360, 4720, 5357, 2319, 1157, 2283, 2339, 1295, 6282, 1568, 2097, 2962, 5663, 6382, 6682, 7248, 3432, 4443, 1250, 6971, 5883, 5897, 3211, 3869, 3119, 3754, 7794, 6019, 2072, 5482, 2309, 6332, 4008, 3024, 355, 3617, 4644, 3875, 6637, 1180, 7615, 1429, 6112, 357, 192, 6117, 1262, 6702, 2105, 56, 4505, 3269, 3705, 7927, 7933, 4989, 1595, 4883, 5489, 1028, 1547, 3575, 1071, 3187, 5619, 1845, 7743, 50, 2123, 1674, 3771, 3643, 4782, 1703, 3737, 7767, 286, 5673, 844, 3422, 3653, 918, 4314, 1465, 1369, 6331, 1388, 3000, 6166, 3110, 6448, 4568, 3783, 6167, 3428, 1214, 5469, 3388, 7768, 6179, 1427, 6172, 6328, 6069, 7022, 6811, 2869, 6965, 975, 12, 5143, 7080, 4415, 7116, 4450, 270, 1844, 6492, 5582, 7100, 3650, 5171, 4752, 5479, 6217, 6856, 6055, 6050, 3876, 4005, 1152, 5002, 1035, 1062, 6668, 2310, 3307, 2042, 6111, 913, 7137, 3139, 7119, 5947, 3610, 1948, 7183, 1315, 1506, 6163, 6369, 6750, 7363, 7138, 5678, 1277, 7619, 6893, 1434, 5916, 6949, 5888, 939, 395, 1592, 6454, 6810, 5742, 7656, 5712, 1132, 5898, 5770, 3953, 3244, 7922, 4014, 3008, 7882, 4164, 4294, 2848, 4516, 2717, 2622, 4880, 4968, 4971, 4992, 5243, 3906, 208, 3848, 3390, 3562, 3591, 3465, 3636, 3644, 3438, 2051, 3817, 3359, 2205, 172, 2305, 1647, 311, 2111, 6733, 7113, 4903, 5465, 5525, 7040, 5375, 1116, 6416, 2580, 3834, 1279, 877, 2849, 1907, 1300, 1122, 6868, 2168, 974, 5553, 6410, 6487, 5523, 6791, 3853, 4723, 2276, 4471, 6999, 6418, 4917, 1431, 1285, 4891, 1980, 6097, 1645, 3072, 4062, 1846, 3086, 3117, 4018, 1138, 3005, 2118, 7881, 5220, 2958, 4227, 2918, 2905, 1309, 2888, 6379, 1332, 4324, 7387, 3994, 3926, 2115, 3164, 7368, 516, 7354, 572, 2035, 7987, 7121, 2039, 746, 747, 7008, 1938, 3719, 7958, 6941, 5558, 5577, 934, 5341, 6766, 5317, 6721, 4384, 1070, 3930, 7533, 3178, 4338, 5464, 6060, 2737, 4478, 2674, 7842, 7608, 2782, 5266, 7823, 1689, 5017, 6016, 6254, 1719, 5870, 354, 2480, 5139, 2153, 4960, 6293, 2150, 5274, 6347, 1656, 6736, 3214, 74, 105, 109, 1782, 2956, 2807, 217, 7905, 5780, 1825, 6875, 5, 1548, 4440, 1087, 6357, 183, 3245, 2142, 1472, 77, 1083, 5674, 2802, 1485, 52, 1282, 3919, 3128, 6017, 5798, 884, 896, 4911, 3744, 3284, 1773, 6943, 2179, 3776, 3513, 5429, 852, 866, 3491, 5071, 3477, 1664, 5076, 3459, 3484, 734, 1722, 5588, 3452, 1934, 1954, 5935, 1607, 7279, 6015, 7347, 3693, 3410, 859, 5999, 6307, 6839, 5719, 2597, 1814, 1196, 6513, 3068, 4083, 1484, 5302, 1283, 2749, 4453, 1569, 6245, 4447, 6391, 1422, 1828, 4296, 4427, 2801, 2847, 4383, 3124, 1163, 4017, 2562, 2457, 3858, 2096, 6782, 2099, 5661, 1029, 3913, 3921, 2465, 1054, 4854, 4844, 4767, 2545, 1528, 3991, 6137, 1508, 2548, 5695, 5892, 3541, 137, 7542, 28, 7494, 31, 48, 7686, 7491, 7720, 7719, 6356, 6516, 2016, 2805, 300, 6311, 953, 3040, 7985, 4729, 1951, 7115, 1203, 6716, 6065, 6057, 159, 5540, 6275, 4756, 7015, 5902, 6731, 7156, 2340, 1513, 2992, 359, 345, 2800, 917, 1103, 3314, 2247, 3397, 234, 868, 283, 4049, 5676, 4107, 4468, 3824, 1655, 3983, 3772, 110, 7122, 2155, 3988, 1385, 3589, 1760, 6547, 2813, 1611, 113, 2323, 6105, 6113, 6745, 308, 3457, 2385, 2007, 7711, 5056, 1076, 1657, 4325, 7124, 4977, 4011, 6265, 276, 6395, 1745, 4514, 7, 3951, 1702, 4735, 814, 3849, 235, 6977, 6800, 317, 880, 3067, 5356, 5400, 5257, 5057, 3548, 316, 5653, 6694, 3002, 6602, 1612, 6257, 4877, 6945, 6812, 5535, 4722, 2902, 2913, 4739, 2897, 3396, 5875, 447, 6018, 4904, 4116, 1168, 6576, 4531, 5799, 7839, 5827, 3029, 2126, 4525, 5895, 2890, 7257, 2351, 2736, 1751, 4510, 4991, 4310, 5689, 4308, 685, 2808, 7787, 5850, 988, 4192, 4183, 5847, 7176, 2350, 1803, 4168, 4166, 4442, 1177, 4162, 7212, 2092, 2752, 2842, 1781, 4490, 1732, 4150, 5864, 7548, 4148, 4402, 7880, 2853, 1146, 6603, 575, 7160, 449, 1049, 4763, 3386, 6774, 5244, 7382, 7820, 3346, 3769, 2267, 25, 3799, 6442, 6466, 7360, 3299, 5445, 1055, 2582, 4692, 2022, 4070, 2415, 6268, 3408, 1240, 4873, 5176, 4905, 7996, 6760, 1995, 360, 4885, 6966, 3502, 1983, 1365, 7764, 3468, 6978, 1031, 2496, 5506, 3670, 1968, 3417, 3692, 1962, 1505, 6164, 4548, 7039, 5664, 5597, 147, 4615, 6929, 3963, 4603, 5642, 3091, 3984, 3152, 6506, 937, 4042, 5080, 4544, 2407, 2627, 7894, 1927, 3076, 6152, 6523, 4063, 3258, 6146, 6706, 3879, 6122, 6828, 7047, 3234, 246, 7831, 748, 2625, 5083, 7126, 7797, 4856, 2724, 4515, 757, 1757, 7811, 5457, 4810, 2675, 7066, 6691, 4759, 5404, 7017, 1931, 1787, 6935, 5289, 2000, 330, 1515, 1175, 6197, 1696, 7553, 3790, 6889, 4233, 6887, 2246, 5092, 3971, 7291, 6051, 6546, 6037, 3036, 5140, 1259, 313, 1154, 950, 2232, 2245, 6337, 7869, 6300, 1150, 6527, 5672, 5485, 4010, 86, 7073, 1304, 3150, 2003, 3684, 6696, 6296, 4875, 4651, 6319, 7935, 340, 3462, 4849, 3815, 6746, 4812, 5245, 6125, 5808, 7174, 7877, 2745, 6591, 4156, 1156, 1695, 6643, 3296, 3368, 3602, 908, 94, 5660, 262, 6352, 2863, 5529, 5549, 6940, 6577, 6094, 3862, 5116, 356, 3947, 6742, 6304, 4512, 3475, 6817, 916, 1534, 1497, 3544, 4463, 1183, 5249, 3504, 3311, 2087, 1382, 6969, 162, 840, 6457, 3434, 1271, 6580, 2387, 6680, 2979, 1558, 1594, 1643, 102, 143, 5603, 3662, 807, 180, 3367, 1529, 5760, 140, 6992, 7840, 3784, 2220, 6193, 119, 6064, 1395, 5531, 6780, 6917, 1764, 6873, 335, 6040, 3100, 6196, 7102, 6705, 4551, 1205, 989, 870, 7648, 2167, 5288, 3495, 3131, 7915, 3363, 2268, 3255, 3843, 3279, 3295, 5763, 6345, 6316, 7076, 6665, 3847, 6009, 4482, 6816, 1940, 4194, 6717, 4809, 6505, 4811, 3909, 2140, 983, 864, 5615, 1705, 3348, 6908, 320, 145, 2131, 5293, 5315, 2001, 966, 5420, 5350, 6827, 5332, 2219, 2139, 2203, 7753, 5439, 5442, 2011, 5368, 7744, 998, 5253, 2037, 2158, 7729, 2120, 7999, 1999, 5981, 1219, 1541, 6086, 1206, 6070, 6061, 1575, 6528, 1606, 5997, 5983, 5969, 6610, 1653, 1684, 5918, 6570, 6572, 7673, 6583, 5874, 1726, 1728, 1731, 6106, 1530, 390, 6120, 6394, 1320, 1334, 1343, 1350, 1361, 1363, 358, 6314, 6434, 1280, 1430, 6226, 6212, 1463, 6203, 1261, 1258, 6464, 6168, 6144, 1235, 6484, 7545, 5835, 5475, 1048, 5618, 5593, 1079, 5583, 5565, 7528, 1068, 1932, 7712, 5554, 1944, 1957, 1752, 5526, 1960, 1039, 5510, 1037, 411, 1034, 5493, 1030, 1025, 7723, 1879, 5646, 5655, 5667, 6617, 1144, 5185, 1770, 1779, 6632, 1126, 5781, 1785, 3538, 5766, 6647, 1809, 5732, 5724, 1110, 1834, 1858, 5692, 1859, 1864, 5684, 258, 5190, 4966, 4792, 2574, 793, 594, 2588, 4693, 3278, 2593, 4353, 2828, 7477, 4359, 7042, 589, 7342, 3872, 4654, 4635, 2629, 2635, 3026, 683, 4389, 2575, 7024, 2482, 801, 831, 2511, 3336, 4798, 4793, 3083, 2526, 4788, 4783, 4333, 7373, 4334, 3323, 4760, 2542, 4135, 4346, 806, 2564, 4724, 4347, 2653, 537, 3219, 3917, 7303, 4089, 7266, 722, 4470, 4399, 720, 2784, 2787, 2789, 4444, 3149, 3146, 7851, 3144, 7274, 4023, 4404, 3106, 7282, 3099, 732, 7150, 582, 2710, 3920, 2687, 2690, 4574, 4571, 7322, 4391, 2704, 2705, 543, 4395, 3184, 7316, 7910, 3177, 4522, 3169, 4511, 2741, 2742, 3746, 7280, 836, 2981, 2985, 3564, 6981, 2383, 7440, 5108, 465, 5007, 893, 2389, 3686, 5110, 2272, 5123, 3414, 4297, 3560, 471, 6909, 5067, 2915, 2961, 4, 3497, 7989, 194, 628, 2363, 4268, 3466, 7779, 2374, 3446, 4271, 3577, 4198, 2375, 5016, 204, 178, 4954, 4888, 4238, 7389, 3727, 2456, 4892, 7805, 609, 3731, 3724, 7445, 4884, 3529, 2850, 3366, 4851, 3543, 4165, 7190, 4906, 6939, 2412, 4153, 2924, 3701, 4946, 6851, 4910, 3402, 4925, 492, 2872, 2440, 7802, 3718, 6951, 3590, 6100, 6635, 1780, 295, 2089, 334, 6895, 919, 3213, 6751, 2851, 7955, 5397, 3704, 7878, 1672, 3004, 6012, 4130, 7655, 3007, 4217, 4090, 1661, 4129, 312, 4095, 4093, 6034, 4076, 1591, 4087, 5970, 307, 4202, 4123, 5184, 4035, 3138, 1471, 3758, 6201, 7613, 6207, 1461, 3381, 3711, 6278, 3697, 1390, 6286, 7968, 7969, 7971, 3657, 7972, 7975, 7981, 3612, 6326, 7994, 6346, 3520, 363, 6372, 364, 6381, 7581, 3328, 3308, 3306, 7926, 6073, 7998, 3998, 1557, 84, 3981, 7639, 6089, 3965, 3198, 6126, 6127, 6131, 6133, 3806, 6139, 3884, 3256, 7930, 3866, 3861, 5930, 3851, 36, 3268, 3275, 7621, 30, 4225, 4396, 5919, 2425, 1978, 4821, 2486, 2463, 4881, 4886, 1990, 1993, 7722, 4890, 1998, 2455, 4899, 2453, 2444, 5453, 4921, 4773, 5521, 2537, 2600, 2616, 5571, 5569, 2613, 2611, 5563, 4673, 157, 1958, 2596, 4690, 2584, 1950, 4738, 4741, 2552, 4927, 5424, 2637, 2414, 5281, 5090, 2144, 2145, 5098, 5099, 2281, 5126, 5130, 5229, 5153, 5162, 5165, 5192, 5174, 5177, 5187, 2338, 5046, 2349, 5339, 5419, 5414, 4961, 2398, 2050, 5011, 2377, 5333, 5041, 227, 2101, 5325, 2369, 2367, 2364, 5038, 2624, 2638, 4235, 7681, 2838, 2832, 4360, 1741, 2815, 4372, 4374, 4375, 4376, 4378, 2812, 4390, 4392, 5821, 5179, 5810, 4398, 1727, 5861, 1724, 4272, 1701, 7873, 4247, 4252, 4255, 2911, 4269, 2893, 1723, 4278, 1710, 4280, 4298, 1713, 5878, 4305, 5806, 264, 2645, 4405, 4529, 1862, 4532, 2721, 5681, 7836, 2700, 249, 2698, 7834, 2669, 5626, 5624, 4605, 5611, 4612, 5598, 4513, 1852, 7694, 1786, 131, 4416, 4421, 4425, 7685, 4430, 4434, 4441, 4498, 1806, 2766, 5750, 4481, 4487, 2756, 5721, 6397, 1981, 519, 1232, 7421, 823, 7509, 837, 6646, 745, 667, 7306, 7474, 6640, 6639, 7370, 6801, 6498, 549, 586, 587, 1211, 754, 658, 7346, 6630, 6818, 6899, 670, 835, 7167, 681, 7270, 475, 476, 478, 7129, 932, 577, 381, 7227, 7427, 624, 559, 6825, 6824, 7425, 6679, 673, 6450, 735, 6515, 7531, 682, 7490, 6604, 497, 7546, 638, 636, 416, 7530, 7377, 7337, 789, 7386, 485, 437, 791, 792, 7330, 7211, 501, 1061, 536, 1053, 7332, 1185, 7462, 643, 6764, 6923, 6924, 6531, 7253, 765, 7405, 418, 6784, 503, 6930, 441, 490, 7323, 650, 6776, 491, 629, 647, 7514, 7340, 6606, 6435, 635, 1292, 7502, 695, 6658, 7573, 566, 7503, 6427, 6415, 370, 1286, 562, 7504, 1298, 6422, 1099, 938, 6401, 696, 7574, 464, 7286, 7570, 701, 7577, 5679, 5849, 1619, 290, 4974, 6974, 7885, 3376, 339, 1742, 1888, 952, 2843, 163, 6860, 6147, 5980, 4348, 1800, 951, 1094, 6551, 2987, 5703, 7345, 230, 3800, 3489, 2875, 6575, 5869, 5343, 3027, 1903, 5128, 6900, 1868, 6662, 1212, 1869, 4940, 876, 7833, 6956, 1502, 4451, 1920, 5887, 7055, 5285, 5151, 2313, 986, 6542, 2396, 6233, 965, 3132, 5915, 3685, 7034, 6673, 2876, 6497, 4400, 4337, 6853, 3935, 5347, 3665, 3649, 3315, 3216, 5792, 1943, 2162, 1487, 1379, 79, 5669, 1307, 5203, 3871, 5668, 1482, 3096, 5717, 6189, 6449, 5643, 4867, 1088, 5951, 1393, 3775, 5767, 949, 3756, 5894, 1370, 2100, 1345, 6297, 6988, 6004, 5682, 2152, 2243, 6280, 3285, 4725, 1264, 7695, 7782, 7611, 1112, 6169, 3515, 3277, 809, 6948, 7765, 188, 5696, 2696, 4871, 7872, 6115, 7863, 314, 5859, 6739, 3532, 53, 5907, 5377, 4157, 7956, 845, 4143, 2192, 1544, 5212, 59, 3500, 1840, 6854, 7849, 5120, 5924, 211, 5033, 3197, 3052, 6937, 6753, 6552, 2373, 7144, 5945, 1831, 3931, 3797, 2725, 3859, 4815, 4489, 4929, 3447, 116, 4677, 4857, 6749, 3646, 4797, 2117, 5367, 6636, 6634, 4949, 6514, 2971, 4660, 3957, 948, 5796, 5848, 1911, 3672, 5863, 2925, 6689, 3344, 4412, 4680, 6360, 6343, 5755, 7091, 1246, 3571, 2859, 1372, 3594, 1428, 225, 6644, 1376, 7084, 6677, 1522, 6488, 1823, 2963, 1375, 4473, 4564, 7083, 7131, 1119, 112, 4177, 3613, 5256, 3503, 2975, 7904, 4863, 6793, 979, 1357, 4742, 1036, 57, 2285, 5520, 1136, 4494, 344, 7607, 5136, 349, 107, 347, 2891, 73, 7775, 4657, 1476, 3837, 6987, 812, 5905, 4562, 3436, 6288, 6669, 2055, 3956, 5194, 2327, 2260, 331, 5129, 5743, 849, 1207, 1383, 3249, 284, 972, 7026, 4652, 7679, 5111, 7242, 5042, 6759, 2216, 4889, 1420, 7704, 1820, 7125, 6767, 5135, 3546, 5219, 7123, 4916, 2160, 5072, 5048, 195, 5210, 6272, 2172, 5522, 5362, 4230, 5300, 328, 123, 4316, 4418, 6544, 6110, 5612, 7749, 2113, 7005, 6910, 5316, 7062, 3034, 4506, 7082, 6787, 7002, 3854, 7977, 7817, 6412, 4507, 4112, 3958, 3820, 6549, 6517, 3996, 305, 13, 3507, 3663, 6700, 1265, 3680, 6302, 6814, 3660, 5670, 6711, 5666, 1946, 3852, 5623, 1899, 5606, 5610, 4865, 3290, 2474, 2464, 3818, 35, 442, 861, 2479, 2490, 4859, 4822, 5641, 1873, 2497, 2460, 3816, 2459, 5584, 1078, 527, 4154, 3822, 3261, 1921, 2503, 440, 1877, 2973, 4167, 1914, 5568, 2454, 4827, 5601, 403, 7349, 5546, 5599, 3855, 4832, 5594, 1926, 5591, 4853, 7934, 614, 694, 5382, 2450, 7761, 2128, 7906, 2132, 2366, 5279, 5034, 581, 7297, 7265, 214, 5264, 2148, 5261, 4006, 213, 6826, 431, 420, 924, 7302, 5301, 2370, 990, 6796, 2098, 181, 7258, 995, 3161, 5005, 3979, 3039, 2371, 897, 5008, 902, 7259, 2376, 5307, 5020, 5304, 925, 7898, 5541, 4019, 5173, 2294, 206, 7772, 4048, 2233, 5163, 5158, 202, 5106, 6858, 5150, 2250, 2279, 5141, 2278, 4060, 4059, 6866, 2298, 3078, 5093, 5078, 2169, 4082, 4024, 928, 5058, 2318, 5214, 4074, 7287, 7499, 2218, 5198, 5195, 569, 560, 5086, 4041, 936, 1001, 3967, 5352, 3966, 3010, 1986, 4134, 4935, 5478, 5477, 1997, 4128, 2418, 4127, 1014, 417, 5466, 7726, 2002, 6768, 7924, 5458, 60, 1984, 7245, 463, 408, 2447, 1953, 238, 2445, 3886, 405, 7717, 6730, 1964, 4922, 1965, 2437, 3235, 1971, 7329, 410, 3231, 3898, 5454, 1008, 5448, 4981, 7733, 7734, 7314, 7735, 5381, 3179, 5378, 2067, 7738, 6789, 2073, 5370, 4114, 546, 5361, 3962, 7739, 3964, 7732, 7731, 3918, 3201, 4125, 5444, 5440, 542, 6931, 5431, 2025, 435, 7320, 545, 3196, 5412, 5411, 1306, 3191, 7798, 6786, 7151, 7357, 3320, 6865, 1417, 5984, 4639, 4641, 2762, 6244, 7603, 3601, 3483, 5975, 5961, 4270, 2829, 5972, 6550, 5968, 5967, 1190, 4653, 725, 6241, 4483, 14, 6541, 2642, 4350, 1446, 1441, 2753, 727, 2757, 2882, 1194, 2758, 2884, 2759, 3412, 2633, 4632, 7966, 7202, 724, 6579, 1179, 1688, 3492, 7960, 7601, 3586, 3583, 3739, 288, 5912, 640, 1697, 2591, 1173, 7384, 7454, 3582, 5901, 7671, 4253, 459, 138, 4458, 495, 7468, 1413, 680, 2907, 3490, 1411, 2605, 5946, 139, 3728, 5941, 2780, 5938, 7209, 3730, 1675, 489, 4288, 4290, 7637, 4558, 7090, 4527, 2695, 4526, 7071, 338, 6470, 4311, 1602, 2689, 1546, 2726, 4520, 7859, 4581, 1560, 1563, 1241, 2858, 7475, 6119, 3632, 665, 1237, 1236, 481, 4336, 2716, 4530, 2715, 664, 3641, 2714, 6129, 2713, 7559, 6490, 2711, 1564, 1566, 6075, 1199, 6035, 4609, 4611, 3419, 6025, 3416, 1598, 6204, 6022, 7177, 4293, 829, 1458, 767, 4291, 6537, 3415, 2879, 6041, 1490, 386, 755, 4306, 7554, 3666, 6066, 739, 2671, 3620, 4301, 2667, 7098, 1578, 4598, 2660, 2839, 1587, 2655, 6578, 7871, 5752, 4787, 7365, 6358, 5811, 3329, 5813, 361, 5817, 3332, 5819, 7012, 5727, 1290, 5726, 1346, 2936, 5741, 2955, 5723, 2528, 6378, 7148, 3335, 7374, 448, 1818, 6614, 7692, 6341, 6613, 7693, 811, 5807, 1137, 443, 5739, 4762, 820, 5738, 5736, 7947, 6641, 703, 1331, 7001, 509, 3518, 5786, 7219, 1325, 4764, 5790, 2543, 7818, 3530, 2529, 2549, 5731, 455, 4786, 4698, 4394, 6648, 1767, 7376, 5718, 6612, 2932, 5872, 6321, 4385, 7215, 7467, 3535, 2796, 7582, 7220, 7826, 3358, 130, 1718, 133, 1167, 4382, 3573, 7030, 2794, 6661, 1811, 4781, 1284, 5886, 4433, 708, 4779, 3550, 689, 5871, 1328, 5851, 1164, 4388, 2799, 3512, 4772, 3796, 824, 4387, 7537, 2964, 367, 3339, 2927, 6605, 3511, 4784, 5853, 2570, 2571, 7449, 1843, 4386, 7379, 2518, 1162, 7538, 3510, 4423, 5866, 2508, 3309, 848, 7649, 6685, 5527, 1783, 6879, 3460, 1316, 5885, 5822, 3891, 7948, 3865, 4683, 943, 1368, 1371, 3263, 115, 3215, 3675, 5789, 5388, 5613, 3205, 6476, 985, 4500, 5287, 7139, 2258, 6237, 5160, 6238, 2, 1355, 7580, 7289, 4475, 2797, 6420, 6230, 567, 6255, 3598, 6330, 6846, 2230, 1407, 3104, 7087, 3070, 4012, 132, 2253, 7424, 5030, 4342, 6815, 6375, 6380, 737, 419, 7575, 2846, 7890, 5276, 7860, 5037, 5271, 4410, 6213, 3990, 1451, 6216, 2149, 7295, 7435, 6990, 4332, 5430, 7549, 4908, 7954, 6727, 1169, 7031, 7670, 1959, 20, 1694, 5504, 4679, 2909, 7516, 6758, 4668, 5470, 3716, 5977, 1012, 7200, 2015, 2413, 2018, 6000, 1939, 3757, 7547, 1889, 1850, 3298, 3819, 4199, 1109, 5728, 5735, 1875, 7532, 6683, 2270, 7369, 4718, 4215, 6626, 1912, 6619, 5585, 6611, 7808, 7021, 4232, 6964, 5842, 6007, 6558, 7065, 6518, 4613, 2649, 3182, 2046, 1590, 1582, 3954, 4113, 3195, 2682, 6084, 322, 890, 6501, 2703, 5323, 4118, 3019, 310, 5417, 1005, 879, 3014, 8, 2357, 179, 4945, 6807, 1553, 5211, 4740, 3251, 315, 4502, 2189, 247, 175, 3303, 6885, 1520, 4957, 7829, 7715, 4780, 3528, 252, 1312, 233, 4902, 4900, 5685, 6597, 6180, 7094, 3867, 1139, 5428, 6473, 5829, 3033, 4625, 2945, 1448, 5052, 4599, 873, 1032, 4636, 3903, 6447, 1424, 3127, 5051, 5460, 6545, 1043, 3143, 2983, 1367, 6185, 3429, 5788, 1387, 1489, 969, 1080, 1389, 6883, 940, 6199, 6104, 5269, 3265, 4637, 2814, 6587, 6512, 6645, 874, 2982, 2974, 5115, 2896, 4648, 182, 2505, 4972, 903, 2384, 2867, 2585, 4855, 2289, 5043, 862, 6954, 4589, 4149, 2997, 4699, 4985, 2288, 2386, 7101, 4685, 4414, 2583, 871, 3009, 4976, 4996, 4274, 7317, 2269, 6813, 1503, 3767, 1740, 1743, 1086, 5314, 6192, 7305, 3723, 7423, 274, 2198, 1775, 6223, 6227, 6239, 3833, 397, 5651, 5659, 1273, 7429, 3629, 6154, 3969, 3860, 5952, 5994, 1609, 1667, 3905, 1669, 1677, 3682, 3874, 1066, 5435, 3664, 1691, 1075, 5408, 1925, 5884, 2080, 1536, 7557, 7740, 2182, 6460, 3382, 1822, 3293, 5202, 3516, 5149, 7769, 956, 6318, 3811, 3496, 2248, 3114, 1391, 1299, 3568, 2252, 1247, 3469, 5614, 1554, 1509, 1663, 5782, 2976, 1348, 4517, 5351, 6508, 3300, 3294, 1527, 5363, 6477, 5608, 4987, 4969, 2231, 6056, 7243, 863, 5543, 6562, 154, 7194, 4407, 3373, 4983, 2399, 7799, 4569, 1539, 5385, 4980, 5374, 6667, 2088, 5657, 4182, 2988, 7134, 5268, 6864, 1449, 1452, 2163, 6256, 4843, 3494, 7020, 6655, 1460, 5705, 3605, 3057, 6511, 4727, 4457, 5704, 5516, 3097, 2197, 6417, 275, 1765, 2187, 1949, 2940, 1915, 289, 6967, 197, 4663, 2870, 5713, 3873, 5471, 4664, 4803, 5065, 817, 5132, 6995, 1293, 7193, 5927, 5764, 144, 6325, 2688, 3997, 4067, 4816, 2103, 4819, 6472, 7751, 1468, 1887, 6200, 5882, 7112, 2296, 1133, 6451, 7460, 1287, 5156, 3742, 1342, 7911, 396, 6225, 2477, 3667, 3828, 1540, 2860, 3115, 3880, 5860, 5680, 3793, 4805, 3857, 3936, 3157, 7153, 1202, 6336, 1140, 3712, 860, 2297, 2991, 3640, 6955, 3125, 1256, 160, 6160, 2308, 15, 3522, 6723, 4840, 1495, 97, 7104, 7154, 11, 1399, 2251, 302, 3995, 7700, 7096, 805, 3553, 352, 2743, 2119, 843, 6925, 4503, 6663, 7897, 6099, 1700, 6997, 3604, 93, 117, 2228, 2143, 3123, 3674, 173, 1895, 1789, 3779, 955, 5488, 3982, 2328, 5751, 5787, 3671, 5776, 3908, 2943, 5762, 3207, 1396, 394, 2864, 3753, 1329, 1358, 1799, 7875, 1412, 4771, 351, 7995, 1344, 3310, 7480, 6998, 6338, 6263, 1141, 4480, 7657, 3679, 4604, 6529, 2880, 3694, 1182, 1604, 4674, 1433, 6005, 1614, 6559, 1624, 4645, 3713, 2620, 4300, 4251, 6092, 4315, 6211, 7543, 3616, 4222, 4650, 1254, 7093, 10, 4715, 6155, 4331, 3352, 3440, 1712, 5899, 260, 1125, 5345, 1985, 2299, 6684, 3077, 3910, 7756, 5511, 7708, 2052, 3055, 2217, 171, 3133, 2989, 3162, 1982, 2084, 5055, 5311, 3192, 4956, 3937, 4894, 892, 245, 6905, 2262, 2273, 2259, 7525, 6688, 5443, 3093, 3044, 4994, 6857, 2500, 3945, 6287, 6867, 6540, 3630, 3978, 3627, 3631, 3970, 3975, 126, 3166, 3974, 2966, 3626, 3622, 584, 668, 7984, 3987, 479, 3041, 4099, 3158, 7181, 4101, 7420, 552, 3461, 128, 554, 7976, 3168, 4318, 3186, 483, 484, 7318, 3190, 4313, 3433, 7412, 3193, 3016, 3661, 3015, 7411, 7866, 657, 3204, 7913, 4122, 656, 4115, 78, 4330, 660, 7463, 7418, 7979, 3638, 3639, 7310, 4094, 7254, 482, 663, 3444, 7416, 7974, 3441, 547, 7973, 7415, 7312, 124, 7304, 4001, 7261, 684, 7857, 7858, 3572, 7158, 3574, 3576, 7436, 687, 3579, 7434, 4032, 7895, 7166, 4373, 4072, 7433, 4370, 4073, 4369, 2818, 3570, 570, 101, 474, 4058, 7448, 7447, 7446, 693, 3084, 4061, 565, 3521, 568, 691, 3082, 4046, 7443, 4045, 564, 7442, 468, 563, 4367, 4031, 4092, 4351, 4022, 675, 7290, 2837, 7292, 3481, 7294, 7901, 3479, 4088, 2820, 7296, 558, 7299, 557, 583, 555, 3051, 3472, 3470, 7288, 2833, 7172, 7426, 4365, 2822, 4030, 579, 4078, 7991, 3058, 4363, 2823, 4029, 2824, 3121, 679, 2827, 7428, 3599, 7171, 4080, 4081, 654, 652, 7970, 3838, 4158, 4159, 2990, 452, 4161, 2930, 3337, 524, 7375, 4226, 7950, 2933, 7235, 4163, 504, 612, 3274, 518, 3326, 3325, 2938, 38, 611, 2928, 634, 3361, 3264, 4244, 532, 22, 4243, 4242, 4241, 3752, 23, 3338, 530, 7344, 2926, 631, 7378, 3761, 24, 3341, 630, 7352, 4219, 7410, 617, 4204, 7222, 7223, 7366, 7458, 3821, 4188, 7355, 3801, 7362, 454, 3812, 3301, 511, 514, 4190, 2970, 625, 512, 4193, 7225, 7367, 4206, 7455, 4174, 2941, 3280, 3281, 7231, 34, 2944, 623, 32, 4173, 3286, 3826, 3321, 7353, 4178, 7229, 4210, 4209, 4208, 7876, 3827, 2922, 7381, 533, 4248, 7925, 2881, 4131, 4287, 4286, 4285, 3222, 4132, 3698, 3413, 4133, 3223, 649, 595, 648, 4279, 3411, 7400, 7399, 7398, 3401, 7251, 7328, 7967, 540, 7252, 7914, 4124, 7918, 71, 626, 3426, 7408, 3421, 539, 7404, 7326, 3681, 3220, 4126, 3420, 487, 488, 3418, 3691, 4276, 7396, 4275, 3733, 3890, 3247, 637, 3001, 4256, 3250, 3378, 7333, 7334, 7335, 3238, 7210, 602, 605, 534, 3738, 498, 3741, 607, 7237, 597, 7390, 4136, 7246, 644, 4137, 3901, 3225, 7395, 7201, 493, 7964, 494, 7962, 4261, 7961, 7392, 642, 3227, 4264, 7870, 3232, 3236, 4262, 1301, 4970, 4401, 5607, 1898, 5622, 1897, 5628, 1892, 5630, 1890, 5633, 5634, 1886, 5638, 5639, 6681, 1876, 1874, 1872, 6678, 1870, 7534, 7701, 1867, 1901, 1906, 7526, 7706, 7527, 1065, 5556, 7710, 5560, 1930, 1073, 5567, 5572, 1924, 5574, 5576, 5578, 5579, 1918, 5586, 5590, 5592, 1913, 1081, 1909, 5677, 1866, 5686, 401, 1810, 5758, 398, 1807, 1798, 5774, 6629, 5801, 1766, 5805, 7544, 5812, 5815, 1763, 1761, 5824, 5825, 5826, 1746, 1739, 5841, 5754, 1812, 7688, 1838, 7536, 1101, 5691, 5694, 7698, 1856, 5698, 259, 1841, 5715, 1817, 1826, 261, 5729, 5730, 5733, 7690, 1113, 1821, 1819, 1059, 241, 1735, 5353, 5359, 2082, 2081, 5366, 6790, 7737, 2066, 2061, 2041, 1004, 7730, 2036, 2034, 5405, 5406, 2033, 2032, 5410, 2031, 6783, 2030, 7511, 5346, 5544, 7741, 2134, 5290, 2133, 2130, 218, 2121, 7750, 5310, 2112, 226, 7746, 5322, 5324, 994, 5328, 5329, 5331, 6799, 5334, 6798, 996, 5416, 5418, 7513, 2028, 7517, 1988, 7721, 5490, 5498, 1979, 5501, 1976, 1973, 1969, 1038, 7521, 1963, 407, 5519, 6732, 7718, 1041, 1050, 5537, 5538, 5481, 1019, 1018, 6777, 2026, 1006, 5425, 2024, 7728, 2023, 5434, 6778, 5438, 5441, 6763, 5446, 6773, 5450, 2014, 5455, 1010, 6770, 5461, 5472, 1738, 1160, 5278, 1501, 7560, 1251, 6178, 7616, 1480, 1478, 1475, 346, 7562, 1266, 1267, 6206, 7612, 6218, 1437, 7563, 7606, 1426, 6246, 1421, 1419, 1500, 6162, 6102, 7626, 1223, 7632, 1224, 1227, 7631, 6118, 1230, 6121, 6486, 6128, 1233, 6483, 6136, 7629, 6138, 1234, 1521, 6141, 1518, 1238, 6148, 1414, 6261, 6264, 7565, 1366, 7590, 7588, 1362, 7571, 1353, 6361, 1338, 6364, 1335, 6366, 1333, 7585, 1326, 6406, 7576, 1324, 6404, 6386, 6388, 1311, 6424, 7592, 6425, 7597, 6266, 1410, 379, 378, 6439, 6281, 1281, 6436, 6289, 6433, 6426, 6432, 6298, 7568, 6301, 1381, 7596, 7594, 6428, 7593, 7634, 6101, 5852, 5926, 7552, 1685, 7666, 6561, 1666, 5950, 1658, 7661, 1186, 6554, 1649, 5959, 1646, 5963, 5964, 5965, 5973, 5974, 1639, 5978, 1637, 1686, 1690, 6098, 5921, 1730, 1161, 5856, 5858, 1725, 6590, 7550, 5876, 1166, 5881, 281, 5891, 1171, 1172, 1178, 5908, 1698, 5913, 6566, 7551, 1181, 1635, 1191, 1631, 5986, 6038, 6039, 6046, 1581, 1579, 6049, 1201, 1576, 6054, 6524, 1574, 6520, 1573, 1572, 1571, 1570, 321, 7641, 1208, 6093, 1213, 6530, 6033, 6532, 1605, 5987, 5988, 5989, 1625, 1623, 1618, 7658, 6001, 6006, 6538, 6030, 6536, 1198, 1601, 6021, 6024, 6534, 6533, 6028, 6029, 2136, 7510, 7451, 4546, 4775, 4776, 4777, 4536, 2530, 2527, 2525, 2521, 827, 4535, 2515, 4533, 828, 2509, 744, 981, 4523, 743, 4807, 4774, 2723, 4770, 2540, 2558, 4737, 4541, 7819, 2547, 2544, 2718, 2541, 2539, 2532, 2538, 4758, 4539, 2536, 2534, 7816, 7086, 4768, 2504, 4818, 2499, 2734, 4858, 2475, 4861, 2473, 4866, 2471, 2470, 2466, 7810, 839, 2458, 7806, 439, 7473, 6961, 2694, 4895, 7487, 2476, 4850, 833, 4834, 4823, 834, 2495, 2493, 4830, 4831, 2727, 2488, 2728, 7097, 4835, 2487, 4837, 4838, 2484, 4518, 7481, 7812, 7013, 2563, 7838, 161, 4617, 4618, 7058, 2644, 2639, 768, 771, 2636, 2634, 4561, 2632, 773, 774, 775, 752, 4640, 777, 2699, 2623, 2647, 2648, 4608, 4586, 2693, 2692, 753, 2684, 2679, 2697, 2678, 2677, 7067, 759, 2672, 2670, 2668, 2665, 2663, 2661, 2656, 758, 779, 150, 780, 2579, 750, 4695, 7078, 4697, 7476, 795, 2581, 4706, 2578, 790, 796, 2573, 4713, 2572, 2569, 2712, 444, 2566, 2590, 2595, 7046, 4666, 781, 2615, 783, 4658, 785, 4661, 2609, 2607, 2606, 788, 2604, 2603, 7041, 4675, 2602, 4678, 786, 2598, 4898, 7486, 174, 6845, 4437, 2793, 2241, 5164, 5167, 5170, 5175, 5178, 5181, 5148, 2226, 6844, 5186, 961, 2221, 5191, 5193, 6837, 2244, 2792, 4435, 428, 5081, 2446, 7781, 201, 7778, 7850, 710, 2301, 427, 7774, 709, 2790, 6869, 7776, 5118, 941, 6861, 2257, 5201, 2210, 714, 7853, 5241, 7506, 6831, 5246, 6830, 7465, 5248, 5250, 7758, 2166, 7141, 5258, 5259, 702, 5272, 5273, 216, 4406, 5239, 5235, 4431, 2178, 7766, 2204, 2201, 5222, 704, 2181, 6835, 5225, 2795, 423, 5227, 4428, 4424, 6834, 4422, 5232, 4420, 210, 4445, 429, 5075, 2404, 2416, 2760, 7470, 2411, 2768, 2408, 4958, 2406, 2772, 4941, 4965, 6926, 4975, 4978, 7469, 4986, 2317, 4466, 445, 2421, 434, 6938, 7488, 7103, 736, 2748, 7472, 2433, 2431, 2430, 4928, 2424, 733, 7110, 4930, 4931, 2427, 4933, 4934, 2426, 2391, 2775, 7072, 6901, 433, 5026, 929, 886, 2783, 915, 5028, 719, 5059, 716, 6898, 7496, 6890, 134, 2341, 4449, 4461, 4462, 5018, 5066, 2776, 4998, 2788, 5001, 5003, 5004, 4464, 5073, 2321, 930, 5006, 5009, 6911, 2381, 5013, 5061, 6183, 987, 3948, 6340, 3702, 2809, 4563, 1491, 7604, 1435, 7074, 3480, 1386, 6299, 332, 5277, 875, 1956, 4848, 5662, 4943, 248, 4967, 2394, 4988, 1077, 3037, 2356, 4180, 3907, 7783, 2303, 68, 2282, 3928, 3094, 5365, 5348, 168, 4802, 800, 816, 2969, 4629, 5903, 1555, 2920, 4734, 6594, 7051, 3088, 1589, 3405, 2012, 2027, 2587, 1023, 927, 2346, 1507, 1744, 2043, 2360, 231, 2077, 2085, 2806, 2874, 2171, 2094, 2108, 3153, 91, 977, 2135, 368, 1337, 371, 2567, 911, 166, 1784, 1797, 3318, 1114, 2965, 1849, 1416, 854, 1098, 1092, 280, 2443, 2442, 1405, 1880, 1882, 1394, 1711, 1526, 1902, 1082, 810, 2852, 891, 1074, 2560, 3048, 1148, 1525, 3999, 5991, 6048, 3976, 7759, 6452, 7788, 6273, 6219, 6170, 6095, 3703, 3902, 5985, 4191, 5865, 5784, 4249, 5779, 5771, 7844, 6693, 6888, 5687, 7068, 7523, 7249, 7217, 7214, 3773, 7196, 7159, 3786, 7060, 6891, 7053, 7033, 6984, 3840, 6936, 3845, 6913, 6892, 7845, 7555, 5683, 4576, 4596, 5369, 4882, 5255, 4887, 7920, 5247, 4979, 5387, 4995, 5040, 5107, 4497, 7936, 5084, 5074, 4751, 4862, 5409, 4354, 7884, 5474, 4732, 4633, 5512, 4327, 5559, 5640, 5463, 3789, 6903, 5747, 1051, 2844, 813, 855, 1837, 5216, 1215, 5707, 3747, 3316, 5929, 5944, 6277, 3362, 2348, 3615, 6174, 2062, 2337, 6320, 3505, 3547, 1317, 2948, 5889, 1603, 6140, 1483, 6194, 2091, 3257, 2176, 1255, 3792, 4577, 4000, 6582, 1108, 3654, 6349, 3677, 3365, 3943, 2343, 6715, 0, 1916, 2840, 6720, 5617, 3651, 191, 3023, 5917, 156, 7188, 6077, 4795, 1093, 5957, 2395, 3683, 3952, 5955, 6707, 1060, 4263, 4876, 2193, 5204, 2264, 5949, 4356, 7745, 6904, 3549, 3856, 4953, 51, 2353, 3305, 151, 3134, 220, 6276, 1753, 1935, 5552, 6290, 3399, 1356, 4108, 4705, 6355, 5645, 3474, 5654, 6103, 6407, 3122, 1549, 1552, 1392, 6014, 265, 7128, 1257, 6500, 6353, 2180, 3203, 842, 6071, 1274, 1217, 5896, 6560, 1129, 5748, 42, 1524, 5508, 6687, 85, 6942, 3085, 2302, 1496, 1380, 3887, 1443, 6724, 5768, 2008, 5215, 3673, 1104, 3372, 4560, 4982, 4393, 2978, 5390, 6584, 3458, 5396, 1195, 5415, 2020, 7757, 4007, 7515, 6496, 4179, 4236, 3625, 4357, 205, 6444, 4750, 6423, 5462, 3726, 6396, 5982, 1121, 1620, 5295, 6747, 1805, 7300, 2972, 1045, 3938, 3941, 7315, 1056, 5284, 4860, 4845, 7385, 4824, 3678, 2127, 3454, 4800, 5308, 6670, 1759, 6659, 7383, 3635, 1996, 6377, 2200, 1596, 6208, 1462, 6202, 4721, 5587, 5710, 4100, 342, 3710, 184, 1883, 4292, 1453, 2589, 4676, 1593, 5709, 7852, 1863, 4672, 4671, 6085, 4662, 1857, 4312, 1754, 5499, 6306, 5804, 392, 3103, 388, 7883, 1952, 5534, 5539, 1832, 5998, 6312, 2550, 2866, 136, 1941, 1736, 1936, 4071, 3069, 7591, 2934, 189, 5557, 6271, 5879, 7796, 1016, 2329, 2326, 632, 4211, 4937, 7216, 872, 7709, 4254, 5069, 5082, 3850, 2306, 1679, 3870, 4578, 5934, 6896, 2292, 7727, 3596, 933, 2722, 846, 946, 2419, 7169, 4990, 7149, 7146, 7135, 271, 7175, 7184, 7186, 7095, 740, 2372, 1790, 7689, 7939, 7037, 7691, 2347, 4547, 5053, 7203, 5103, 5079, 6805, 7264, 3916, 5131, 2211, 5147, 3450, 2910, 999, 7256, 6779, 6772, 6003, 185, 957, 6188, 6503, 6008, 6802, 4745, 3915, 237, 7192, 2912, 1291, 1917, 1894, 3113, 4649, 3554, 1531, 7940, 5836, 6737, 5528, 6714, 5548, 236, 5740, 6874, 7789, 7540, 3645, 4567, 6752, 3808, 6198, 3740, 3709, 2330, 5102, 2359, 3782, 1671, 4744, 6294, 89, 303, 3353, 2947, 186, 7908, 1583, 6574, 2577, 1486, 350, 5207, 7748, 1771, 3451, 4403, 1945, 5263, 803, 4104, 2810, 2059, 2287, 1373, 6660, 3409, 5656, 62, 6411, 1289, 244, 399, 3424, 3431, 2284, 2291, 5449, 6480, 5862, 2388, 4140, 4009, 6114, 7114, 324, 6385, 95, 5068, 4519, 6143, 385, 2967, 1617, 6339, 1347, 3488, 3471, 5109, 6359, 3210, 6850, 1349, 2968, 108, 329, 1762, 3540, 4584, 5909, 3385, 199, 6335, 3349, 3377, 6489, 1397, 3608, 3154, 7023, 1447, 5205, 5360, 5105, 1717, 4582, 111, 3545, 6963, 6713, 7937, 1885, 6303, 6151, 6631, 3609, 5734, 1794, 1792, 1776, 1768, 7837, 7848, 1772, 1839, 5759, 301, 1853, 2324, 4963, 7943, 2382, 5015, 5035, 2333, 4528, 4495, 2320, 5087, 5088, 2304, 2740, 4501, 7946, 4919, 4579, 2462, 2502, 4799, 2519, 4790, 4753, 3542, 4600, 2554, 2555, 2557, 7988, 4731, 4703, 4496, 5104, 5693, 7868, 5533, 7879, 5545, 1947, 7874, 4322, 2861, 2754, 1919, 1910, 4302, 5652, 129, 4283, 4352, 2004, 5451, 5403, 5392, 90, 5386, 2074, 5355, 5312, 2129, 66, 2170, 3558, 2237, 5125, 5119, 2929, 4623, 3932, 377, 1106, 1095, 7283, 374, 6284, 7273, 592, 3194, 1040, 6741, 372, 4228, 7247, 1439, 7240, 7618, 1454, 1466, 3043, 1017, 6765, 4103, 460, 4056, 3087, 3763, 3968, 7500, 7696, 469, 7343, 1253, 1260, 1272, 6598, 6624, 1131, 544, 6392, 3463, 3732, 1319, 1336, 7308, 6363, 4043, 393, 4051, 1352, 3092, 6171, 3371, 7168, 7064, 7803, 1644, 6947, 3881, 6897, 3658, 298, 1659, 6918, 1680, 1720, 1682, 885, 7814, 881, 7652, 6927, 1709, 6933, 306, 4176, 5993, 3781, 4170, 825, 1523, 5855, 1532, 3228, 7676, 7199, 6823, 6087, 1562, 7697, 7643, 7677, 1580, 1586, 3893, 1588, 3892, 6010, 3327, 3656, 4595, 3340, 348, 3343, 7145, 2249, 6803, 2817, 3922, 4757, 5936, 3116, 5054, 6797, 3011, 5114, 6088, 6091, 2265, 7792, 4696, 2322, 5154, 2400, 5157, 4952, 6794, 282, 125, 1013, 341, 970, 5697, 3042, 7106, 1708, 7713, 2953, 3555, 5931, 3606, 4260, 3312, 2892, 7651, 4189, 5877, 2903, 5996, 2993, 6849, 3032, 3035, 2202, 375, 4064, 7048, 5547, 6657, 4627, 6638, 7893, 1134, 1135, 6599, 3823, 4380, 7752, 5854, 1244, 7285, 1096, 3804, 6269, 6953, 3071, 1024, 4893, 1929, 2865, 6957, 3062, 1398, 6862, 5600, 6743, 2183, 257, 6507, 2009, 64, 3391, 2175, 1115, 3669, 164, 3537, 3600, 6409, 2240, 5340, 3105, 319, 4687, 337, 353, 7669, 7982, 7035, 7665, 7668, 4796, 5823, 6876, 2908, 4065, 6755, 2222, 2223, 4476, 1069, 5956, 4069, 3183, 6848, 5394, 6880, 6165, 3882, 3863, 2942, 1351, 3282, 6285, 3271, 3262, 3260, 6757, 3794, 2017, 6588, 3217, 3749, 1200, 2049, 3020, 3387, 169, 3556, 869, 982, 6313, 818, 6243, 6240, 7609, 6236, 6222, 6149, 5497, 6074, 5711, 1788, 165, 291, 2079, 7983, 2157, 6994, 6962, 899, 6882, 6847, 984, 2405, 7205, 2215, 5240, 7949, 6413, 222, 6695, 5305, 87, 808, 7364, 6557, 1187, 1197, 6468, 1511, 3539, 2883, 4091, 3619, 4328, 4077, 4197, 3795, 3254, 3025, 4340, 3259, 3832, 3283, 4109, 2345, 1249, 6440, 6443, 6453, 3118, 5121, 6461, 6390, 6429, 4626, 4013, 2751, 6376, 1225, 3141, 6510, 6526, 1192, 5101, 1174, 3989, 5095, 3986, 1231, 4052, 6373, 5159, 3046, 2225, 6210, 3050, 6220, 6221, 3054, 5166, 4085, 6249, 6258, 2765, 6370, 1409, 1401, 3066, 6291, 4055, 4054, 1360, 5138, 1159, 4050, 6365, 2739, 3973, 1158, 6738, 1026, 1021, 3212, 2352, 3218, 6771, 1007, 992, 6822, 6841, 3233, 6843, 945, 3241, 6881, 6886, 920, 5021, 5014, 6907, 898, 5010, 6914, 4997, 4993, 1033, 1042, 6607, 1044, 6609, 6620, 3160, 5196, 3165, 2733, 2732, 3972, 6653, 2731, 2730, 2729, 1111, 3171, 3173, 3175, 2325, 3960, 5062, 2331, 2719, 6698, 1072, 4542, 6719, 4097, 6158, 6181, 5699, 5629, 1891, 1881, 1878, 2114, 5675, 2886, 5690, 4429, 2887, 2889, 1854, 4277, 2106, 4273, 2894, 5296, 4436, 5294, 5292, 1833, 1829, 1813, 5773, 2138, 4257, 5575, 5320, 1498, 5364, 5402, 5413, 2070, 2071, 2029, 4364, 4362, 5452, 5371, 2826, 5459, 2831, 2835, 5573, 1991, 2836, 1977, 1975, 4345, 5524, 5338, 4339, 4329, 5550, 1933, 5562, 5267, 1774, 4234, 1550, 1622, 2184, 1613, 4169, 6027, 4146, 6052, 6058, 4144, 6078, 2196, 4141, 1538, 5814, 1533, 4465, 6134, 3021, 6135, 3022, 4111, 6150, 2212, 2214, 6921, 3030, 1627, 1629, 1636, 5976, 4231, 2931, 5830, 1750, 1748, 5839, 2937, 5846, 4220, 4214, 4213, 5893, 2950, 5906, 1692, 5237, 1678, 5236, 4203, 5230, 4186, 1650, 5960, 5962, 5971, 2390, 3924, 499, 591, 588, 7667, 3690, 7271, 7272, 7646, 3407, 4585, 2481, 3406, 2483, 7638, 561, 326, 3355, 7636, 7633, 556, 4836, 590, 7674, 221, 2654, 2522, 4878, 7185, 3637, 7198, 2680, 639, 7736, 4872, 4870, 7207, 242, 4607, 2652, 599, 7702, 7678, 2472, 7244, 7307, 550, 548, 7311, 7397, 7432, 7437, 7519, 4806, 7456, 2524, 7459, 7492, 7493, 2513, 2514, 4590, 430, 425, 7507, 7508, 7512, 7518, 3272, 7520, 2673, 7587, 2492, 7625, 529, 2494, 7620, 525, 7348, 7356, 513, 7529, 362, 7583, 373, 387, 506, 391, 7371, 2501, 4711, 3778, 676, 3552, 55, 7921, 61, 2640, 7018, 7919, 72, 797, 7907, 3509, 3810, 2691, 784, 92, 7054, 7899, 7891, 769, 7170, 4950, 7007, 4936, 4646, 7997, 4630, 858, 857, 7986, 2631, 850, 7941, 3526, 838, 37, 4638, 4566, 4570, 39, 6985, 6986, 3829, 7938, 7867, 7886, 3581, 718, 4918, 2599, 3624, 7770, 4707, 209, 215, 3319, 2448, 7162, 4907, 7163, 2452, 4901, 7755, 7164, 3324, 7786, 7130, 723, 7830, 3803, 3584, 4686, 4619, 7081, 141, 146, 2586, 7089, 742, 7815, 2646, 170, 731, 729, 4920, 3374, 240, 2075, 4467, 1668, 19, 228, 267, 5395, 2044, 6142, 1425, 1297, 4573, 3354, 6348, 3825, 1184, 7056, 971, 7063, 4556, 7088, 856, 1067, 3955, 2334, 4868, 3109, 3102, 6471, 4555, 5880, 3762, 1928, 6968, 2295, 2234, 4580, 1022, 3896, 847, 5794, 3791, 3302, 2315, 904, 148, 2977, 5995, 88, 6697, 2819, 7117, 2236, 382, 1440, 7143, 7888, 6593, 3717, 7900, 914, 4583, 5483, 3095, 7903, 5487, 865, 5515, 7855, 3185, 3514, 7075, 3868, 967, 5671, 3939, 3304, 1955, 7953, 5551, 5473, 3904, 1922, 6912, 6788, 912, 7011, 83, 1009, 3253, 819, 2045, 7029, 7931, 4265, 1084, 3403, 7647, 5939, 3112, 4624, 7645, 318, 5958, 6342, 333, 1400, 3060, 3714, 6674, 7602, 4155, 6252, 6231, 380, 4142, 1445, 7380, 6116, 1464, 6190, 7662, 1294, 1276, 2951, 3473, 2895, 3614, 5714, 6654, 7133, 7136, 6176, 1153, 3453, 2914, 5797, 223, 4003, 3142, 7208, 3135, 3443, 7705, 7703, 6475, 3652, 3659, 6922, 1769, 5349, 2254, 4413, 4593, 5134, 5024, 4955, 2392, 2685, 4702, 2095, 4717, 4684, 4545, 4409, 3745, 6902, 947, 6543, 6107, 6002, 5200, 2355, 3248, 1303, 3748, 5145, 3764, 167, 3129, 3392, 5900, 5609, 7108, 3642, 49, 1242, 76, 968, 6469, 6354, 2994, 7120, 5765, 1364, 5309, 3706, 4309, 6928, 5596, 959, 3842, 2565, 7650, 1816, 2755, 4947, 5706, 1085, 6522, 5616, 3478, 1747, 1842, 851, 6950, 1835, 5904, 6371, 6762, 3595, 4004, 6878, 7617, 3398, 158, 1836, 5744, 4716, 7828, 6175, 1923, 5297, 1847, 6690, 4419, 1848, 3985, 7683, 4964, 6493, 5318, 1470, 7784, 6535, 6728, 3147, 1188, 1777, 4736, 5783, 4704, 6224, 279, 1218, 1473, 3056, 5632, 3611, 2873, 6502, 6479, 4084, 6564, 7790, 3439, 1755, 4492, 4733, 3467, 3634, 6710, 2935, 212, 376, 5922, 5555, 7457, 2735, 5423, 707, 2995, 7263, 4647, 6650, 6011, 3557, 6781, 1384, 2986, 6616, 2006, 3559, 70, 887, 4175, 3075, 1992, 5077, 3759, 1585, 6045, 4053, 1, 4397, 2058, 2057, 2811, 7191, 4879, 6324, 6806, 2048, 4119, 5022, 7165, 6076, 7945, 2708, 2709, 700, 3788, 2190, 7394, 2485, 4184, 7044, 4504, 5514, 5032, 5933, 4472, 2643, 7556, 2960, 3725, 2093, 6157, 5532, 3174, 4785, 4942, 4719, 1015, 7854, 1942, 6919, 5152, 1824, 4187, 7052, 1670, 5000, 2517, 5122, 4075, 5948, 4939, 415, 6350, 1314, 3689, 2159, 4914, 7707, 3899, 7187, 5914, 1270, 5800, 4408, 4488, 3379, 1488, 1477, 3437, 993, 1665, 6182, 4594, 5793, 4015, 3755, 6044, 5380, 900, 3883, 3864, 1994, 120, 1142, 2804, 6308, 3499, 1908, 3525, 6242, 3980, 7942, 3925, 63, 7182, 6808, 6993, 82, 3798, 5492, 6615, 3073, 1651, 5206, 3914, 3912, 1632, 2516, 7422, 2086, 7483, 4455, 2512, 1987, 3802, 7070, 1642, 7059, 457, 7485, 4801, 5286, 1310, 3565, 4349, 1687, 3384, 118, 3807, 2959, 6884, 7887, 106, 1402, 103, 6769, 3506, 4999, 400, 7535, 2090, 6153, 7896, 5943, 5505, 96, 6656, 7522, 4794, 5146, 4814, 5344, 901, 7309, 507, 7944, 1378, 2998, 596, 2999, 43, 41, 4869, 1354, 2358, 2628, 620, 5398, 6310, 910, 5990, 2468, 7204, 7957, 3770, 7965, 4896, 6894, 2053, 3252, 6083, 3331, 1127, 1551, 4151, 6829, 1002, 3523, 6399, 7319, 6664, 5358, 5476, 7293, 7909, 7912, 4656, 2078, 2186, 2379, 2013, 1610, 5218, 4841, 4160, 1278, 4842, 4152, 5447, 923, 1599, 1003, 7932, 7262, 2362, 1827, 122, 4682, 6871, 6726, 822, 7003, 5778, 4610, 2885, 4246, 6704, 2141, 4295, 7675, 5270, 1323, 4559, 3423, 2923, 5802, 198, 7785, 5803, 5644, 5809, 2146, 3199, 4688, 1228, 6734, 4229, 7009, 5688, 6209, 1459, 5050, 5722, 5725, 7716, 2290, 232, 2403, 5745, 5027, 2368, 2124, 250, 5283, 5753, 4710, 272, 1052, 1327, 7699, 2906, 4474, 3456, 6214, 1455, 219, 1855, 5303, 6725, 4499, 5262, 4614, 3623, 1492, 4224, 5580, 6467, 4216, 6465, 6259, 6177, 4550, 155, 1714, 7627, 935, 5112, 152, 4691, 3846, 7832, 2952, 883, 7847, 3493, 3720, 4944, 1699, 5910, 3888, 4534, 7028, 2417, 4552, 4319, 5213, 7809, 6362, 7660, 1479, 6186, 5188, 1737, 5252, 4102, 177, 1893, 1749, 6932, 4446, 3894, 7644, 5636, 5595, 4746, 3270, 5857, 190, 6946, 6344, 5029, 2235, 4984, 5137, 7092, 5155, 4897, 6205, 7147, 1537, 5124, 6228, 3047, 5127, 907, 6383, 802, 3090, 5117, 6504, 5094, 6585, 2109, 5100, 7763, 4712, 4714, 3449, 1204, 5749, 5113, 5049, 1791, 5791, 4237, 6491, 3695, 6474, 7653, 2954, 7827, 4689, 2855, 3585, 2314, 9, 17, 7952, 2065, 1120, 4642, 45, 4643, 5373, 5436, 6652, 4655, 5480, 5354, 1149, 5502, 5507, 4417, 6459, 263, 1577, 4145, 1000, 3357, 1616, 5937, 1654, 4454, 4852, 7489, 3735, 1640, 1559, 5942, 4553, 2917, 104, 3107, 1600, 2354, 4456, 2856, 6260, 6351, 5060, 4591, 5604, 867, 5700, 4543, 6494, 4554, 5845, 6463, 6852, 299, 7152, 3031, 1123, 7654, 2165, 6229, 3897, 6568, 3531, 3476, 6053, 3765, 6642, 389, 3597, 58, 3273, 7107, 99, 2010, 153, 4659, 5494, 1107, 4847, 1151, 7132, 3063, 4557, 5045, 3045, 7069, 285, 277, 2342, 4223, 1457, 5840, 1676, 6842, 2336, 4962, 1467, 3400, 7049, 6456, 229, 383, 6975, 6333, 6445, 6809, 5260, 5940, 6754, 6317, 804, 6187, 2040, 7916, 7642, 1248, 6414, 3345, 6068, 1715, 2280, 962, 5509, 2227, 6555, 1519, 1905, 6722, 6676, 5777, 4808, 882, 7822, 6080, 3588, 2845, 6633, 6708, 5542, 6322, 2194, 3889, 6567, 273, 6389, 1308, 3288, 269, 2332, 2980, 3760, 1275, 6980, 1305, 1097, 1143, 3923, 2076, 2996, 3707, 5209, 1210, 1243, 6840, 114, 176, 6960, 5923, 193, 909, 4509, 3380, 6982, 7045, 2195, 6309, 3375, 1543, 3942, 67, 1117, 4694, 5873, 6675, 2110, 3993, 4748, 5867, 2275, 7268, 1090, 5890, 3209, 4597, 5953, 1904, 384, 4747, 1693, 3722, 1683, 4195, 5843, 5834, 3148, 7659, 4282, 3445, 7760, 7714, 3188, 243, 4708, 3442, 254, 5757, 255, 256, 1802, 5772, 2137, 1047, 7682, 278, 3427, 1865, 7771, 6703, 2286, 6699, 3929, 7663, 3464, 2191, 3927, 4709, 6042, 5702, 3551, 7057, 964, 3805, 7889, 7025, 5342, 7902, 4485, 4948, 3246, 954, 1474, 6920, 5495, 5484, 5085, 2019, 6215, 6625, 5422, 4479, 6622, 6959, 6972, 6368, 1514, 5063, 1403, 1130, 6059, 6063, 3959, 5384, 2256, 6079, 7197, 3156, 2449, 1545, 3835, 2271, 6274, 4477, 4912, 6403, 6279, 6292, 135, 7118, 297, 3200, 1340, 142, 2188, 3536, 6, 4540, 4631, 7824, 2116, 5665, 5096, 1089, 3992, 1937, 4307, 5097, 6671, 1176, 7865, 4304, 4343, 7795, 7825, 4508, 203, 4289, 3519, 6556, 3089, 1124, 4749, 6996, 7000, 4755, 7600, 5925, 5928, 2409, 2173, 815, 5197, 4171, 3297, 1512, 6804, 1517, 7189, 976, 3313, 3240, 4016, 6334, 3687, 292, 5142, 5144, 905, 5868, 3202, 6482, 6262, 3287, 4743, 1359, 4549, 323, 2916, 1209, 2185, 6400, 3900, 3949, 1469, 3708, 6628, 4634, 5828, 6627, 3159, 6267, 4117, 6519, 2380, 5820, 6305, 2147, 6709, 2311, 3276, 6863, 7780, 4448, 3517, 65, 6569, 1660, 80, 2174, 6184, 1615, 1091, 6047, 4575, 3003, 6916, 294, 6748, 5605, 1027, 1499, 3774, 6013, 3028, 6327, 3700, 3768, 75, 69, 6989, 5785, 2177, 6596, 6191, 5920, 7105, 2102, 3425, 5393, 6247, 7605, 3715, 1716, 888, 1556, 54, 3049, 6195, 309, 3777, 6062, 6043, 3655, 2900, 5217, 991, 6595, 3317, 3155, 2871, 997, 7032, 6462, 4620, 7155, 4669, 5182, 944, 6329, 889, 6096, 3111, 3351, 1245, 6156, 1597, 1318, 4320, 196, 3448, 5716, 3534, 200, 3524, 3676, 7754, 2005, 3587, 3393, 2060, 3785, 2224, 1432, 1493, 2064, 4105, 5180, 2857, 4565, 1436, 7929, 4789, 6952, 2047, 7835, 895, 6295, 3080, 4057, 5391, 5389, 5025, 4628, 6877, 3243, 2263, 963, 3533, 2877, 7036, 2904, 4185, 1648, 4817, 3364, 304, 3696, 5831, 296, 3347, 5775, 7680, 4874, 1795, 7180, 3809, 224, 4909, 5649, 4915, 7109, 5208, 7099, 7085, 7077, 5648, 7043, 5954, 3487, 4587, 1608, 1057, 1102, 2335, 1063, 6571, 3180, 3136, 6419, 1100, 2274, 6649, 5047, 1216, 2069, 3356, 3435, 942, 2300, 6145, 3647, 3895, 1423, 4491, 2239, 5242, 7495, 6756, 5602, 3839, 6235, 6232, 1252, 2238, 3836, 2344, 7862, 6944, 1408, 3593, 4728, 6159, 4754, 7505, 878, 2104, 2107, 5319, 4317, 3189, 1662, 3844, 2868, 4196, 1442, 1707, 2125, 6455, 4267, 1456, 5647, 4096, 1704, 3395, 3787, 853, 7004, 2199, 5044, 207, 3814, 6712, 7014, 1450, 7742, 4913, 6672, 402, 5036, 1900, 5620, 239, 6173, 3831, 6973, 1444, 7027, 6976, 3053, 4207, 2957, 1064, 894, 1851, 5372, 7959, 1145, 1189, 2469, 7255, 2551, 6553, 4040, 5265, 7928, 7864, 5427, 46, 1296, 4245, 3137, 2154, 3108, 2068, 7260, 4002, 3527, 5254, 29, 293, 7664, 7267, 6393, 3933, 1302, 2746, 6795, 5467, 1729, 906, 4411, 5517, 7388, 7127, 7993, 1155, 3580, 4813, 6692, 6565, 2213, 6283, 6819, 3934, 3736, 6485, 5491, 5251, 4486, 505, 6744, 1796, 7213, 7990, 5023, 517, 5992, 6855, 6402, 6108, 3940, 5708, 4700, 47, 6525, 3699, 5838, 2662, 5844, 7610, 6539, 7614, 2657, 2161, 2939, 2949, 7640, 2156, 3404, 2664, 7635, 4452, 4765, 2946, 3120, 1706, 2984, 7402, 7391, 7372, 1058, 4820, 3944, 7351, 3750, 3751, 7313, 2491, 2489, 551, 4839, 4172, 7595, 3163, 6718, 7278, 7277, 7276, 7275, 2478, 7269, 580, 2747, 585, 3350, 2676, 1584, 7414, 7431, 2507, 467, 7589, 365, 369, 4769, 3389, 5911, 5932, 3383, 4205, 7539, 3729, 4200, 2785, 409, 4791, 3950, 414, 2520, 4592, 3946, 1652, 3734, 6509, 7497, 4588, 7484, 7452, 3370, 7444, 5837, 7725, 1193, 7892, 3501, 3569, 5518, 3567, 5513, 2841, 98, 3485, 4670, 3172, 4665, 5503, 3508, 5496, 4344, 3498, 5530, 5337, 4335, 5336, 127, 7856, 2854, 5327, 4323, 2594, 7843, 6600, 2592, 5091, 3486, 3563, 5486, 1989, 5379, 3977, 7992, 1118, 6621, 3167, 7980, 7963, 18, 4622, 1147, 7951, 5070, 27, 2816, 5399, 5468, 5376, 40, 5407, 44, 5433, 6608, 5437, 2825, 5456, 2803, 5089, 4355, 7917, 4524, 5589, 3176, 5832, 2791, 5769, 7684, 5756, 253, 251, 1815, 5746, 3482, 4726, 2720, 2568, 2899, 5720, 1830, 266, 268, 3430, 5282, 1793, 5275, 1778, 7672, 4239, 4602, 3688, 5816, 6548, 1758, 1756, 2151, 2293, 4147, 5291, 7747, 1884, 7813, 3607, 4616, 4537, 7807, 7800, 5625, 1896, 7793, 5627, 3618, 187, 5637, 4303, 4299, 6686, 2878, 6586, 5313, 7777, 5650, 7773, 4284, 5658, 1860, 5306, 5299, 2122, 6573, 2576, 4864, 1128, 2209, 3013, 6251, 2393, 6934, 5039, 3059, 4079, 2277, 1222, 7179, 4973, 1438, 1011, 6970, 2402, 5168, 3830, 2683, 677, 6979, 5172, 2229, 6253, 2242, 1415, 4066, 5019, 3878, 2706, 3877, 7195, 3081, 6437, 6906, 3079, 1046, 2702, 4068, 3074, 3065, 3064, 1404, 6082, 1406, 6441, 6270, 6090, 4959, 2707, 2451, 4106, 3130, 787, 6130, 782, 7111, 7050, 3206, 2206, 2207, 2208, 4924, 6481, 7079, 749, 6478, 1510, 1516, 4110, 4938, 7061, 6124, 1020, 715, 1229, 6991, 5183, 1263, 688, 4493, 2410, 4572, 3291, 3292, 7016, 713, 699, 7019, 7142, 3813, 705, 3017, 5199, 6123, 711, 6315, 760, 1322, 3766, 6499, 4044, 6072, 1567, 3885, 931, 978, 3101, 6408, 4484, 958, 6374, 1341, 960, 6387, 6832, 1313, 6836, 5031, 6870, 3098, 2467, 3229, 4047, 6820, 6859, 6384, 2365, 5133, 1220, 3237, 2266, 4459, 3145, 6109, 6915, 3780, 343, 3267, 980, 3140, 2770, 2626, 799, 2650, 6398, 3633, 4281, 4266, 3628, 2769, 26, 6421, 4432, 7006, 3038, 33, 4426, 1861, 2038, 1481, 4368, 798, 4038, 5701, 4021, 5298, 4098, 5401, 7010, 4438, 2630, 6761, 4381, 6618, 5761, 1804, 4259, 772, 2422, 4379, 1801, 770, 6821, 2423, 6838, 3230, 2559, 4258, 766, 4036, 764, 763, 762, 4034, 3181, 2561, 1808, 2773, 776, 2361, 21, 7724, 2898, 4538, 794, 4020, 6458, 6833, 4371, 7038, 2420, 2771, 4037, 2901, 1239, 6161, 4377, 778, 7978, 4606, 1321, 2608, 821, 6601, 4341, 121, 5012, 2763, 7861, 5335, 3061, 4326, 5330, 2261, 2614, 2738, 4027, 2830, 7846, 5326, 4321, 2764, 7841, 5561, 3170, 1339, 2601, 6438, 2378, 2798, 6430, 6431, 2641, 922, 3566, 1974, 1972, 3221, 1970, 1967, 2610, 4621, 1966, 2761, 1961, 2612, 81, 926, 3561, 3578, 2834, 4358, 761, 6581, 2821, 2401, 5621, 2621, 841, 5631, 5426, 4701, 5421, 6446, 5635, 4086, 1418, 3621, 921, 3239, 832, 3126, 830, 4366, 826, 4521, 1170, 7801, 4028, 7804, 2021, 5564, 5566, 5570, 5161, 3224, 4039, 4361, 5581, 6250, 2767, 7821, 3841, 2617, 2618, 6367, 3226, 3961, 2701, 4026, 4025, 2619, 5321, 600, 4250, 646, 1561, 3334, 502, 1628, 5223, 645, 2681, 7403, 496, 6081, 4033, 1630, 4181, 7401, 2779, 641, 5221, 508, 510, 7361, 7359, 2498, 7358, 515, 7206, 7350, 520, 521, 522, 523, 4825, 3333, 7406, 2774, 461, 653, 466, 7441, 655, 7450, 462, 3006, 7407, 458, 5224, 7453, 5979, 1638, 453, 7439, 1634, 470, 7438, 472, 473, 2506, 651, 477, 7430, 1633, 480, 7419, 7417, 7413, 7409, 486, 4826, 526, 1626, 573, 7233, 578, 6023, 576, 615, 574, 616, 528, 571, 4846, 6020, 7232, 618, 619, 613, 7234, 7236, 6026, 610, 7238, 608, 7239, 7250, 6031, 606, 6036, 593, 604, 603, 7241, 598, 621, 7281, 622, 1565, 4828, 7341, 531, 7339, 7338, 7336, 535, 7331, 7327, 538, 7325, 7324, 541, 7321, 633, 7284, 4829, 2781, 7218, 7221, 1621, 553, 4833, 7301, 627, 7224, 7298, 7226, 7228, 7230, 2510, 451, 450, 712, 2666, 706, 2750, 3018, 7622, 7623, 7624, 7569, 2441, 7628, 7630, 717, 2686, 1721, 2744, 2777, 4761, 7599, 7598, 698, 697, 2535, 7586, 4766, 7584, 2533, 4120, 366, 7579, 7578, 692, 2546, 4218, 721, 4923, 4932, 6701, 2921, 2556, 756, 2428, 2429, 751, 4439, 5818, 4926, 4601, 2432, 601, 741, 2439, 738, 2434, 2435, 730, 2436, 728, 1734, 1733, 726, 2658, 6132, 2659, 4221, 2438, 7572, 1226, 7461, 4139, 662, 2461, 7498, 1221, 7501, 426, 424, 690, 666, 422, 421, 669, 5228, 2523, 432, 661, 5966, 3330, 436, 659, 438, 1641, 2778, 5226, 7482, 7479, 7478, 7471, 446, 7466, 7464, 6521, 7178, 413, 1681, 2786, 3721, 7567, 7566, 2531, 7564, 4778, 4212, 7161, 5238, 7561, 686, 4121, 7558, 5234, 412, 7541, 4201, 3012, 678, 5233, 5231, 404, 7524, 406, 7173, 674, 4138, 672, 671, 7393]\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('f_order.txt',f_order)\n",
    "print(f_order)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
